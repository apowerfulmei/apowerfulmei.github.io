[{"content":"syzkaller syzlang 今天开一个新坑，我们来分析一下syzkaller的syzlang机制，这也是syzkaller设计上非常巧思的一个部分。我们将会看到，一个简单的txt文件，最终是如何被syzkaller构造为一个包含了详尽参数的系统调用并在qemu中执行的。\n","date":"2025-09-29T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/syzlang/","title":"syzkaller的syzlang机制探索"},{"content":"Syzkaller Testcase Minimization 这里开一个新坑，来探讨一下syzkaller测试用例最小化是如何实现的。\n最小化的意义 首先，为什么我们需要进行测试用例最小化。关于最小化的研究最早可以追溯到Zeller的文章Yesterday, my program worked. Today, it does not. Why?，文章中提出的Delta-Debug方法对后续的研究工作都有着极大的影响。\nSyzkaller是如何进行最小化的 Syzkaller对测试用例的最小化的主要功能集中在prog/minimize.go文件的Minimize函数中，这个函数会接收四个参数：\n参数 描述 p0 要简化的测试用例序列 callIndex0 目标系统调用下标 mode 简化模式 pred0 可以理解为验证函数，验证简化后的程序功能 函数最终将返回简化后的p0以及callIndex0。\n接下来我们将具体分析该函数，可以分为两个部分来看，一个是系统调用序列的最小化，另一个是系统调用参数的最小化。\n系统调用序列最小化 这一部分工作旨在尽可能移除无关的系统调用而仍使测试用例保留原有的功能（触发崩溃或维持覆盖率）。\n这部分功能由removeCalls函数实现，我们可以将其分为三个部分：切割、无关系统调用剔除、遍历筛选。\n1、切割\n首先，函数会移除所有在目标系统调用之后的系统调用，因为大部分情况下，这些系统调用不会影响目标系统调用的状态。\n1 2 3 4 5 6 7 8 9 10 11 if callIndex0 \u0026gt;= 0 \u0026amp;\u0026amp; callIndex0+2 \u0026lt; len(p0.Calls) { // It\u0026#39;s frequently the case that all subsequent calls were not necessary. // Try to drop them all at once. p := p0.Clone() for i := len(p0.Calls) - 1; i \u0026gt; callIndex0; i-- { p.RemoveCall(i) } if pred(p, callIndex0, statMinRemoveCall, \u0026#34;trailing calls\u0026#34;) { p0 = p } } 2、无关系统调用剔除\n随后，将调用函数removeUnrelatedCalls，移除和目标系统调用无关的系统调用。\n它首先调用函数relatedCalls，生成一个 map[int]bool 类型字典，字典表示每个系统调用和目标系统调用是否有关，随后遍历整个测试用例，将无关的系统调用删去，并测试功能是否完整。\nrelatedCalls函数会首先调用 uses 函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 func uses(call *Call) map[any]bool { used := make(map[any]bool) // 遍历所有的参数 ForeachArg(call, func(arg Arg, _ *ArgCtx) { switch typ := arg.Type().(type) { case *ResourceType: a := arg.(*ResultArg) used[a] = true if a.Res != nil { used[a.Res] = true } // args that use this arg for use := range a.uses { used[use] = true } case *BufferType: a := arg.(*DataArg) if a.Dir() != DirOut \u0026amp;\u0026amp; typ.Kind == BufferFilename { val := string(bytes.TrimRight(a.Data(), \u0026#34;\\x00\u0026#34;)) used[val] = true } } }) return used } 提取出目标系统调用使用的所有资源，将其存放在used map中。随后遍历所有其他系统调用，同样提取其使用的资源used1，将其与used进行比较，如果used1使用了used中使用过的资源，则认为该系统调用是相关的，并将used1合并到used中。\n3、遍历筛选\n随后，函数会倒序逐个移除系统调用，如果发现移除后，测试用例原功能丧失，则保留该系统调用，跳过对下一个系统调用进行测试。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 for i := len(p0.Calls) - 1; i \u0026gt;= 0; i-- { if i == callIndex0 { continue } callIndex := callIndex0 if i \u0026lt; callIndex { callIndex-- } p := p0.Clone() p.RemoveCall(i) //移除克隆者的系统调用 if !pred(p, callIndex, statMinRemoveCall, fmt.Sprintf(\u0026#34;call %v\u0026#34;, i)) { continue //功能丧失则跳过 } p0 = p callIndex0 = callIndex } 系统调用参数最小化 这一部分改天更新。\nSyzkaller的最小化场景 Syzkaller最小化的场景有如下几种：Fuzz运行时、崩溃复现\nFuzz运行时 这一部分我们可以看job.go中的代码，从它给prog.minimize传递的pred函数可以发现，这里最小化的功能完整性体现在经过最小化之后，目标系统调用的覆盖率并没有减小。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 p, call := prog.Minimize(job.p, call, mode, func(p1 *prog.Prog, call1 int) bool { if stop { return false } var mergedSignal signal.Signal for i := 0; i \u0026lt; minimizeAttempts; i++ { ... if !reexecutionSuccess(result.Info, info.errno, call1) { // The call was not executed or failed. continue } // 获取目标call执行后的signal thisSignal := getSignalAndCover(p1, result.Info, call1) if mergedSignal.Len() == 0 { mergedSignal = thisSignal } else { mergedSignal.Merge(thisSignal) } // signal没有发生变化，signal的长度相等 if info.newStableSignal.Intersection(mergedSignal).Len() == info.newStableSignal.Len() { ... return true } } ... return false }) 系统调用与系统调用之间存在着隐式与显式的依赖关系，一个系统调用可能会对另一个系统调用产生一些影响，使其执行后的覆盖率发生变化，经过最小化处理后，测试用例会删去那些对目标系统调用无关的系统调用。\n崩溃复现 这一部分内容我们可以参考syz-repro工具的原理，在一个测试用例触发崩溃之后，syzkaller会进行最小化，提取出能出发崩溃的最小测试用例。\n在实现上和上一个流程基本相同，但在调用Minimize函数时，会将callIndex设置为-1，这将跳过切割与无关剔除步骤，直接遍历每个系统调用，观察删去该系统调用之后，崩溃是否还能成功触发。\n","date":"2025-07-01T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/syz-minimization/","title":"Syzkaller Testcase Minimization"},{"content":"PWN Web 我将在这里记录pwn.college中和web相关部分的练习。\nPlaying With Programs - Talking Web 这一章节涉及到的是一些web相关的程序以及命令的基础用法，为后面进阶的内容打基础。\nlevel1 - level4 这部分内容比较简单，就跳过了。\nlevel5 - level6 这一关用到了netcat，也就是nc。netcat提供了一个和server交互的窗口用于构造请求。\n首先连接server：nc 127.0.0.1 80，连接完成以后，按照如下格式构造请求：GET / HTTP/1.1。分别代表请求类型，路径，协议。随后netcat会自动构造完整的请求。\nlevel6 同理，只不过多了一个/verify路径：GET /verify HTTP/1.1 。整个命令可以用一行表示 echo -e \u0026quot;GET /verify HTTP/1.1\\n\u0026quot; | nc 127.0.0.1 80。\nlevel7 这一关使用 curl 构造请求：curl 127.0.0.1:80/complete 。\ncurl直接使用时，构造的是GET请求。加上\u0026ndash;data时，构造的是POST请求。\nlevel8 这一关使用python写一个小脚本。\n1 2 3 4 5 #!/usr/bin/python import requests response=requests.get(\u0026#34;http://127.0.0.1:80/challenge\u0026#34;) print(response.content) level9-level11 这几关需要设置特殊的header，指定header中的host。Host的作用是让server知道请求的是哪一个网站，因为一个IP可能对应多个域名，server需要指导用户请求的域名到底是哪一个。\nlevel9 使用python。\n1 2 3 4 5 6 7 8 9 #!/usr/bin/python import requests header = { \u0026#34;Host\u0026#34;:\u0026#34;webhacking.kr:80\u0026#34; } response=requests.get(\u0026#34;http://127.0.0.1:80/submit\u0026#34;, headers=header) print(response.content) level10 使用curl设置header Host。\n1 curl -H \u0026#34;Host:net-force.nl:80\u0026#34; 127.0.0.1:80/task level11 使用netcat设置请求头。\n1 echo -e \u0026#34;GET /fulfill HTTP/1.1\\nHost: 0xf.at:80\\n\\n\u0026#34; | nc 127.0.0.1 80 level12 这一关提到了一个问题，就是路径可能是包含空格的，这种情况下使用nc构造请求时，要将路径中的空格用编码代替将其连接起来，否则会出现解析错误。\n1 2 echo -e \u0026#34;GET /progress%20request%20qualify HTTP/1.1\\nHost:challenge.localhost:80\\n\\n\u0026#34; | nc 127.0.0.1 80 level13-15 这几关提到了parameter问题，即GET请求的参数问题。使用方式也很简单，在路径末尾使用 ?para=value 即可。\nlevel13：curl -H \u0026quot;Host:challenge.localhost:80\u0026quot; http://127.0.0.1:80/gate?unlock=pwgklefy\n当然，参数可能是不只一个的，这种情况下用\u0026amp;将参数分隔开即可，注意之间不要加空格。\nlevel14：\n1 echo -e \u0026#34;GET /authenticate?secure_key=jcbaywzw\u0026amp;private_key=miwgzszt\u0026amp;access_code=buadbiky HTTP/1.1\\nHost:challenge.localhost:80\\n\\n\u0026#34; | nc 127.0.0.1 80 level15：\n注意这里需要将IP用双引号括起来，因为\u0026amp;在shell中有特殊的含义，会出现错误。\n1 2 curl -H \u0026#34;Host:challenge.localhost:80\u0026#34; \u0026#34;http://127.0.0.1:80/progress?keycode=wrgcvc sy\u0026amp;security_token=zlptrsug\u0026amp;secret_key=eectkeks\u0026#34; level16-level22 这几关涉及到了POST请求的form填写。\nlevel16很简单，在网页填个表格就可以了。\nlevel17使用curl完成任务：curl -H \u0026quot;Host:challenge.localhost:80\u0026quot; -d \u0026quot;pass=wrxfcbng\u0026quot; http://127.0.0.1:80/challenge\nlevel18使用netcat：\n1 2 3 4 5 6 POST /pass HTTP/1.1 Host: challenge.localhost:80 Content-Type: application/x-www-form-urlencoded Content-Length: 15 verify=kuzyuwlx level19使用python：\n1 2 3 4 5 6 7 8 9 10 #!/usr/bin/python import requests header = { \u0026#34;Host\u0026#34;:\u0026#34;challenge.localhost:80\u0026#34; } response=requests.post(\u0026#34;http://127.0.0.1:80/fulfill\u0026#34;, headers=header, data={\u0026#34;access_code\u0026#34;:\u0026#34;dezevikr\u0026#34;}) print(response.content) level20，这一个要求用firefox浏览器发送一个POST请求，不过其实仍然可以用python等工具完成这个任务，只用在User-Agent字段中加入Firefox就可以了。\n1 2 3 4 5 6 7 8 9 10 #!/usr/bin/python import requests header = { \u0026#34;Host\u0026#34;:\u0026#34;challenge.localhost:80\u0026#34;, \u0026#34;User-Agent\u0026#34;:\u0026#34;Firefox\u0026#34; } response=requests.post(\u0026#34;http://127.0.0.1:80/progress\u0026#34;, headers=header, data={\u0026#34;secure_key\u0026#34;:\u0026#34;cfezlwph\u0026#34;}) print(response.content) level21 使用curl完成表格多内容的POST请求：\n1 curl -H \u0026#34;Host:challenge.localhost:80\u0026#34; -d \u0026#34;hash=abnydllx\u0026#34; -d \u0026#34;unlock=hoskplkb\u0026#34; -d \u0026#34;auth_key=wknbddgj\u0026#34; http://127.0.0.1:80/check 对于多个form数据，用多个-d表示\nlevel22 使用netcat完成多表格任务：\n1 2 3 4 5 6 POST /validate HTTP/1.1 Host: challenge.localhost:80 Content-Type: application/x-www-form-urlencoded Content-Length: 64 unlock_code=vbemwqtf\u0026amp;unlock=wxqdlpqz\u0026amp;pin=irdvpzgf\u0026amp;token=eiiddxbd level23-level25 URL 重定向（也称为 URL 转发）是一种为页面、表单或者整个 Web 站点/应用提供多个 URL 地址的技术。HTTP 对此操作有一种特殊类型的响应，称为 HTTP 重定向（HTTP redirect）。\nlevel23使用netcat处理重定向：\n1 2 3 4 5 GET / HTTP/1.1 Host: challenge.localhost:80 GET /uVbqQpyn-fulfill HTTP/1.1 Host: challenge.localhost:80 level24，使用curl进行处理，curl的-L选项，可以自动处理重定位问题：\n1 curl -L -H \u0026#34;Host:challenge.localhost:80\u0026#34; http://127.0.0.1:80/ level25，使用python就更简单了，requests库会自动处理redirect的情况：\n1 2 3 4 5 6 7 8 9 #!/usr/bin/python import requests header = { \u0026#34;Host\u0026#34;:\u0026#34;challenge.localhost:80\u0026#34;, } response=requests.get(\u0026#34;http://127.0.0.1:80/\u0026#34;, headers=header) print(response.content) level26-level28 这几关加入了cookie。\nlevel26:\ncurl的-c可以将cookie保存到一个文件，-b则是指定文件内容作为cookie。\n1 2 curl -c cookies.txt 127.0.0.1 curl -b cookies.txt 127.0.0.1 level27:\n1 2 3 4 nc 127.0.0.1 80 GET / HTTP/1.1 Cookie: cookie=xxx level28:\n1 2 3 4 5 6 7 8 9 10 #!/usr/bin/python import requests header = { \u0026#34;Cookie\u0026#34;: \u0026#34;cookie=x\u0026#34; } response=requests.get(\u0026#34;http://127.0.0.1:80/\u0026#34;, headers=header) print(response.content) level29-level36 level29，这一关使用python requests完成，requests似乎也有针对state的功能，所以代码很简单，仅用requests发送请求即可。\n1 2 3 4 5 #!/usr/bin/python import requests response=requests.get(\u0026#34;http://127.0.0.1:80/\u0026#34;) print(response.content) level30，这一关要求我们对1337端口进行监听，运行/challenge/client客户端以后，会发送带有flag的请求。\n1 nc -l 1337 level31，在server端进行一个重定向。\n1 2 3 4 5 6 7 8 9 10 11 import flask import os app = flask.Flask(__name__) @app.route(\u0026#34;/\u0026#34;, methods=[\u0026#34;GET\u0026#34;]) def redirector(): return flask.redirect(f\u0026#34;http://challenge.localhost:80/attempt\u0026#34;) app.secret_key = os.urandom(8) app.run(\u0026#34;localhost\u0026#34;, 1337) Web Security - Intro to Cybersecurity Path Traversal 1-2 这两关与路径相关，我们在request中加入../即可挣脱出server设置的路径限制，对任意其他文件进行访问。\nlevel1:\n1 2 curl http://challenge.localhost:80/blob/..%2F..%2Fflag curl --path-as-is http://challenge.localhost:80/blob/../../flag 如果我们直接运行curl http://challenge.localhost:80/blob/../../flag，路径最终会被解析为/flag，会出现这个问题的原因是curl会对路径进行简化，将../合并，因此我们可以通过将字符转为编码以解决此问题。此外，我们也可以用curl的flag --path-as-is 解决此问题。\nlevel2：\n1 curl -v http://challenge.localhost:80/data/fortunes/..%2F..%2F..%2Fflag 从level2的server源码requested_path = app.root_path + \u0026quot;/files/\u0026quot; + path.strip(\u0026quot;/.\u0026quot;)可以观察到，相较于level1，level2将path首尾的 . 和 \\ 字符删去了，我们只需要在路径首部加上一个存在的文件夹即可绕过。根据观察，在/challenge/files路径下存在一个fortunes文件夹，我们可以借此绕过检查。\nCMDi 1-6 ","date":"2025-06-30T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/hello-pwn-web/","title":"pwn.college web"},{"content":"清理var目录 清理过程 今天运行我的主机的时候突然提示var目录占满了，使用df -h查看，19G空间都被占满了。\n随机我准备对var目录进行清理，到目录下查看存储量占用时，却发现当前的文件根本没有占用那么多空间。\n按理来说还有十几G的空间才对。\n查阅资料发现当进程打开了某个文件时，只要该进程保持打开该文件，即使将其删除，它依然存在于磁盘中。这意味着，进程并不知道文件已经被删除，它仍然可以向打开该文件时提供给它的文件描述符进行读取和写入。这个文件仅对该进程可见，对其他进程不可见，因为已经删除了其相应的目录索引节点。这也就是存在着幽灵文件占用/var目录磁盘空间的原因。\n我使用命令lsof | grep delete查看是否有进程在占用已经删除了的文件，发现果然如此。\n将这些进程kill之后，磁盘空间果然得到了释放。\n参考 https://blog.csdn.net/ithomer/article/details/8649706\n","date":"2025-06-16T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/clean-var/","title":"var目录清理"},{"content":"BRF 简介 BRF: Fuzzing the eBPF Runtime 是一个针对ebpf runtime组件的模糊测试工具。它旨在解决syzkaller对ebpf模糊测试低效的问题，从程序语义、程序依赖、程序执行三个要点出发，生成了有高verifier通过率、以及丰富语义（即包含了一些列helper与map操作）的C程序，并与syzkaller结合，对ebpf进行模糊测试，大大提升了代码覆盖率，并发现了6个新的ebpf漏洞。\n仓库地址：https://github.com/trusslab/brf\n环境搭建 基础复现流程 BRF仓库的README文件提供了详细的复现流程，可以直接按照这个流程走下来。不过在这个过程中，我仍然遇到了一些难以解决的问题。\nBRF编译问题 在make BRF源代码时，会产生报错：\n这个错误产生的原因是libbpf组件没有被正确地配置，我为此提交了一个PR，解决的办法也很简单，下载最新的libbpf并安装即可：\n1 2 3 4 5 git clone https://github.com/libbpf/libbpf.git cd libbpf/src make make install make install_uapi_headers C代码编译问题 按照BRF的配置，生成器生成的ebpf C代码会在$BRF_WORKDIR下保存，并被挂载到Qemu中，使用clang-16进行编译，生成.o文件。但是实际运行过程中，我发现编译过程并没有被正确执行，可执行文件没有被生成，fuzz流程陷入停滞。\n手动启动Qemu后，我尝试在虚拟机内用clang-16编译C文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 qemu-system-x86_64 \\ -m 2G \\ -smp 2 \\ -kernel $KERNEL/arch/x86/boot/bzImage \\ -append \u0026#34;console=ttyS0 root=/dev/sda earlyprintk=serial net.ifnames=0\u0026#34; \\ -drive file=$IMAGE/bookworm.img,format=raw \\ -net user,host=10.0.2.10,hostfwd=tcp:127.0.0.1:10021-:22 \\ -net nic,model=e1000 \\ -virtfs local,path=$KERNEL,mount_tag=host0,security_model=mapped,id=host0 \\ -virtfs local,path=$BRF_WORKDIR,mount_tag=brf,security_model=mapped,id=brf \\ -enable-kvm \\ -nographic \\ -pidfile vm.pid \\ 2\u0026gt;\u0026amp;1 | tee vm.log mkdir /mnt/brf_work_dir mount -t 9p -o trans=virtio,version=9p2000.L brf /mnt/brf_work_dir clang-16 -g -O2 -D__TARGET_ARCH_x86 -I/usr/include/$(uname -m)-linux-gnu -Wno-compare-distinct-pointer-types -Wno-int-conversion -target bpf -mcpu=v3 -c ./prog_1869aed7db619f2f.c -o test.o 发现确实编译存在问题，似乎也是libbpf的配置问题，但是在前面的基础流程中明明已经安装了libbpf和头文件。不过为了解决这个问题，我还是尝试安装了libbpf-dev。\n1 apt install libbpf-dev 成功解决了这个问题。\nC代码语法错误问题 我发现在生成的C文件中有一些匪夷所思的语法错误，在生成char *类型的变量时，正确的定义方式应该类似于char v[8]=...，但实际上变量的定义方式却是char %!p(string=v)[8]=...。\n源码中关于这一部分代码的内容在 prog/brf_legacy.go#L1308 中：\n1 2 a.Name = fmt.Sprintf(\u0026#34;v%d\u0026#34;, p.VarId) a.Prepare = fmt.Sprintf(\u0026#34;\tchar %p[%d] = {};\\n\u0026#34;, a.Name, varSize) 看起来也并没有什么不妥，为什么会生成这样语法的代码暂时未可知，我的解决办法简单粗暴，修改源代码，识别这样的错误语法并进行修正。\n在 prog/brf_prog.go 中，writeCSource函数会将生成好的C代码写入文件，我们只需在它写入文件之前将代码字符串改为正确的就可以。我添加了一个函数fixCharError，它使用正则表达式匹配错误代码，并修改为正确的格式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 import ( \u0026#34;encoding/gob\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; \u0026#34;regexp\u0026#34; ) func fixCharError(content string) string { fmt.Printf(\u0026#34;I am trying to fix this: %s\u0026#34;,content) pattern := regexp.MustCompile(`%!p\\(string=(\\w+)\\)\\[(\\d+)\\]`) // 执行替换操作并返回结果 newContent:=pattern.ReplaceAllString(content, \u0026#34;$1[$2]\u0026#34;) fmt.Printf(\u0026#34;I fix this: %s\\n\u0026#34;,newContent) return newContent } func (p *BpfProg) writeCSource() error { var progSrc string if (p.UseTestSrc) { progSrc = testSrc } else { progSrc = p.genCSource() } progSrc = fixCharError(progSrc) f, err := os.Create(p.BasePath + \u0026#34;.c\u0026#34;) if err != nil { return err } defer f.Close() _, err = f.WriteString(progSrc) return err } Qemu内存大小问题 解决了上述问题之后，按理来说，应该可以正常运行并编译生成可执行文件了，但是虚拟机仍然不断产生崩溃，观察了log之后，发现是虚拟机内存不够导致的，修改一下config文件就可以解决啦！把mem从2048修改为4096。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { \u0026#34;target\u0026#34;: \u0026#34;linux/amd64\u0026#34;, \u0026#34;http\u0026#34;: \u0026#34;127.0.0.1:56741\u0026#34;, \u0026#34;workdir\u0026#34;: \u0026#34;$SYZKALLER/workdir/bookworm\u0026#34;, \u0026#34;kernel_obj\u0026#34;: \u0026#34;$KERNEL\u0026#34;, \u0026#34;image\u0026#34;: \u0026#34;$IMAGE/bookworm.img\u0026#34;, \u0026#34;sshkey\u0026#34;: \u0026#34;$IMAGE/bookworm.id_rsa\u0026#34;, \u0026#34;syzkaller\u0026#34;: \u0026#34;$SYZKALLER\u0026#34;, \u0026#34;procs\u0026#34;: 8, \u0026#34;type\u0026#34;: \u0026#34;qemu\u0026#34;, \u0026#34;vm\u0026#34;: { \u0026#34;count\u0026#34;: 4, \u0026#34;kernel\u0026#34;: \u0026#34;$KERNEL/arch/x86/boot/bzImage\u0026#34;, \u0026#34;cpu\u0026#34;: 2, \u0026#34;mem\u0026#34;: 4096, \u0026#34;brf_workdir\u0026#34;: \u0026#34;$BRF_WORKDIR\u0026#34; } } 运行效果 解决了上述问题以后，BRF可以正常跑起来了，在$BRF_WORKDIR目录下也可以看到正常的C代码以及可执行文件了，可喜可贺。\n这里我使用的commit是 047d1c9a3e47722ae94afb9f0247a1057c323df3 。\n不过相信聪明的你也已经发现了，为什么coverage是0？\n这是因为在这一个 commit 中，WorkQueue loop相关的代码被注释掉了，triageInput函数不会被执行，也就不会收集覆盖率以及扩充语料库。\n从commit的注释\u0026quot;TEST: disable mutation\u0026quot;似乎可以看出，这个提交只是为了测试brf生成程序以及执行的能力，那我们转移到上一个commit a1f51c55c2c01b5959cfbfc9e44559da5d48551c 再运行试试。\n转移到这个commit再运行以后会发现，BRF在给系统调用syz_bpf_prog_load等传递参数时，由于参数（形如：/workdir/prog_xxx.c）的值会触发syzkaller中对escapingFilename的检查，因此我们需要将相关的检查都注释掉，程序才可以正常运行。\n经过这样一系列的操作之后，我们终于可以看到一个正常运行的BRF：\n覆盖率\n语料库\n","date":"2025-06-14T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/hello-brf/","title":"BRF复现"},{"content":"Docker使用 第一次接触Docker，是在本科做seed lab实验的时候，迄今仍与我的学习科研紧密相关。不过过了这么久，也没有将我的一些使用心得记录下来，今天在这里开个帖子，记录一些Docker的基础用法，也借机探讨一下更深层次的技术与知识。\n","date":"2025-06-11T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/hello-docker/","title":"Docker的用法"},{"content":"本地大模型调用 最近用Lora微调了一个小模型，生成一些小程序，记录一下我是怎么在本地部署使用的。\n实验环境 A800 80G GPU Qwen3 1.7b\n使用模型进行推理 大模型部署好以后，怎么调用大模型进行推理工作呢？整个流程可以分为4步：\n初始化 构建输入 大模型生成 解析输出 初始化 在这一步，我们将加载本地大模型和分词器，使用Hugging Face的from_pretrained函数。\n1 2 3 4 5 6 model = AutoModelForCausalLM.from_pretrained( \u0026#34;./Qwen\u0026#34;, device_map=\u0026#34;auto\u0026#34;, trust_remote_code=True, ) tokenizer = AutoTokenizer.from_pretrained(\u0026#34;./Qwen\u0026#34;) 构建输入 在这一步，我们构建prompt作为输入，首先构造一个基础的消息文本。\n1 2 3 4 messages = [ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: f\u0026#34;{prompt}\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: f\u0026#34;{prompt_u}\u0026#34;} ] 然后用分词器构造template，将文字文本转化为大模型可以处理的输入格式。\n1 2 3 4 5 6 7 8 text = tokenizer.apply_chat_template( messages, tokenize=False, add_generation_prompt=True, enable_thinking=False ) model_inputs = tokenizer([text], return_tensors=\u0026#34;pt\u0026#34;).to(device) 看看model_inputs直接打印出来输出的内容。\n可以看到分词器将文字转化为了模型可理解的数字序列，每个数字对应分词器词汇表中的一个词/子词。\ntokenize=False参数会让函数以文本的形式输出结果，否则将以id的形式输出结果。\nadd_generation_prompt=True会在输出的结果中增加一个assistant的操作，这里我们将text以文本的形式打印出来看看。 enable_thinking则是决定是否要启动大模型的思考模式，启动以后会延长思考时间，这里我直接关闭了。\n使用模型进行推理 这一步，我们将上一步得到的输入传递给大模型进行推理，得到推理结果。\n1 2 3 4 5 generated_ids = model.generate( model_inputs.input_ids, max_new_tokens=MAX_LENGTH, temperature=1.0, ) 这里输出的generated_ids也是以id的形式展现的，要使用tokenizer将其转换为自认语言。\n解析输出 这一步，我们将大模型的输出解码，转为自然语言。\n1 2 3 4 5 generated_ids = [ output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids) ] response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0] 推理加速 跑着跑着，我就发现一些不对劲了，怎么生成速率这么慢？我统计了大模型进行10次推理任务所需的时间，生成一个1500 token长度的程序得花上37s，这对吗？\n这不对，要知道我用的是个小模型，结果速度还不如网页大模型。\n后面找到了一些加速的方法，请容我细细道来。\n增大 batch size 简单来说就是在tokenizer中添加多个请求内容，让大模型同时处理，生成多个response。最大化GPU计算单元利用率​。这个过程很像并发。\n使用多个GPU 这自然就没什么好说的。\n完整程序代码 初始版本 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig from peft import LoraConfig, get_peft_model, PeftModel import torch import random import time model = AutoModelForCausalLM.from_pretrained( \u0026#34;./Qwen\u0026#34;, device_map=\u0026#34;auto\u0026#34;, trust_remote_code=True, ) peft_config = LoraConfig( task_type=\u0026#34;CAUSAL_LM\u0026#34;, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1, target_modules=[\u0026#34;q_proj\u0026#34;, \u0026#34;v_proj\u0026#34;] ) model = PeftModel.from_pretrained(model, \u0026#34;lora_adapter10-30\u0026#34;) print(\u0026#34;load peft\u0026#34;) tokenizer = AutoTokenizer.from_pretrained(\u0026#34;./Qwen\u0026#34;) prompt = \u0026#34;your system prompt\u0026#34; prompt_u = \u0026#34;your user prompt\u0026#34; MAX_LENGTH=1500 def predict(messages, model, tokenizer): device = \u0026#34;cuda\u0026#34; text = tokenizer.apply_chat_template( messages, tokenize=False, add_generation_prompt=True, enable_thinking=False ) model_inputs = tokenizer([text], return_tensors=\u0026#34;pt\u0026#34;).to(device) attention_mask = torch.ones(model_inputs.input_ids.shape,dtype=torch.long,device=\u0026#34;cuda\u0026#34;) generated_ids = model.generate( model_inputs.input_ids, attention_mask=attention_mask, max_new_tokens=MAX_LENGTH, temperature=1.0, ) generated_ids = [ output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids) ] response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0] return response save_dir=\u0026#34;./seeds/\u0026#34; total=0 for i in range(10): start_time=time.time() messages = [ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: f\u0026#34;{prompt}\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: f\u0026#34;{prompt_u.format(num=random.randint(5, 40))}\u0026#34;} ] response = predict(messages, model, tokenizer) end_time=time.time() total += end_time - start_time print(f\u0026#34;Generation time: {end_time - start_time:.2f} seconds\u0026#34;) response_text = f\u0026#34;\u0026#34;\u0026#34; LLM:{response} \u0026#34;\u0026#34;\u0026#34; print(response_text) file=f\u0026#34;{save_dir}seed_{i}.txt\u0026#34; with open(file, \u0026#34;w\u0026#34;) as f: f.write(response) print(f\u0026#34;average generation time: {total/10:.2f} seconds\u0026#34;) 参考 ","date":"2025-06-10T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/hello-local-llm-predict/","title":"调用本地大模型进行predict"},{"content":"PDM使用 PDM是一个python包管理器，不过它不是一个虚拟环境，它可以将依赖安装到项目本地的__pypackages__目录，而非全局目录，从而避免污染全局环境并且实现项目隔离。\n在PDM环境下，项目将优先从__pypackages__中搜索包，实现的原理就是在全局的 site-packages 目录之前加上项目目录里的__pypackages__路径，使得__pypackages__的搜索优先级高于全局的 Python 环境。\n目前我只写了一些初级的用法，后面我会随着我的深入使用更新我的博客。\n下载与安装 使用pip下载，可能会出先网络连接不成功，下载失败的情况，这种情况指定国内源即可：\n1 2 pip install pdm pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple pdm 使用 pdm install速度慢处理 指定pdm使用国内源：\n1 2 pdm config pypi.url https://pypi.tuna.tsinghua.edu.cn/simple 创建项目 创建项目的时候会让依次输入使用的python解释器版本、项目名、邮件等等信息，一板一眼确实挺不错的。\n1 2 mkdir my-project \u0026amp;\u0026amp; cd my-project pdm init init成功以后会在目录下创建下面的三个文件：\n.pdm-python\n.pdm-python中存放了python解释器的路径\npdm.lock\n所有软件包及其版本 包的文件名和哈希值 用于下载包的源 URL 每个包的依赖项和标记 1 2 3 4 5 6 7 8 9 10 11 # This file is @generated by PDM. # It is not intended for manual editing. [metadata] groups = [\u0026#34;default\u0026#34;] strategy = [\u0026#34;inherit_metadata\u0026#34;] lock_version = \u0026#34;4.5.0\u0026#34; content_hash = \u0026#34;sha256:5e86f537f04c413e1ae880b74cc0ddbde0cac75b48683e80298d9a986d7e06c5\u0026#34; [[metadata.targets]] requires_python = \u0026#34;==3.12.*\u0026#34; pyproject.toml\npyproject.toml中则存放了一些相关信息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [project] name = \u0026#34;test\u0026#34; version = \u0026#34;0.1.0\u0026#34; description = \u0026#34;Default template for PDM package\u0026#34; authors = [ {name = \u0026#34;apowerfulmei\u0026#34;,email = \u0026#34;1234@qq.com\u0026#34;}, ] dependencies = [] requires-python = \u0026#34;==3.12.*\u0026#34; readme = \u0026#34;README.md\u0026#34; license = {text = \u0026#34;MIT\u0026#34;} [tool.pdm] distribution = false 依赖项管理 增加依赖项 1 2 3 4 5 6 7 pdm add packages/localpath/url pdm add pandas pdm add pandas==2.2.2 pdm add ./package pdm add \u0026#34;https://github.com/numpy/numpy/releases/download/v1.20.0/numpy-1.20.0.tar.gz\u0026#34; pdm add \u0026#34;git+https://github.com/pypa/pip.git@22.0\u0026#34; add的参数可以是包的名称，可以是本地包的路径（本地路径要以./开头，否则会被视为普通包的命名），可以是URL，也可以是VCS 依赖项。\n增加依赖项的时候指定版本或许会是个好习惯。\n移除依赖项 1 pdm remove pandas 更新依赖项 1 pdm update package 将依赖项更新到更新的版本。\n配置项目 更改pdm配置 1 pdm config 下载依赖并使用pdm环境 1 pdm install 执行命令，pdm将下载pyproject.toml中的依赖项。\n此外，配置环境的方法有两种，分别是虚拟环境和PEP 582环境：\n虚拟环境下将创建一个.venv目录，目录中存放了下载的各种依赖包，可执行以下命令进行操作：\n1 2 3 4 5 # 列举虚拟环境下的依赖项 pdm venv list # 激活虚拟环境，test为项目名称 eval $(pdm venv activate for-test) PEP 582环境将创建一个__pypackages__目录，目录下存放各种依赖包。在PEP 582环境下执行python命令如下：\n1 pdm run python3 test.py pdm run会做两件事：1、在执行命令前，插入 __pypackages__ 目录到 PYTHONPATH 中；2、在执行命令后，删除 PYTHONPATH 中的 __pypackages__ 目录。\n一些方便的方法 配置已有项目 有时候我们会在创建了一个包含大量包的python项目后才想起来使用pdm进行包管理，这种情况应该怎么做呢？\n可以先用pigar生成一个requirements.txt文件：\n1 2 pip install pigar pigar gen 然后直接import即可。\n1 pdm import -f requirements ./requirements.txt 不过实践证明pigar创建的requirements所包含的依赖不一定齐全。\n参考 https://pdm-project.org/zh-cn/latest/ https://geekdaxue.co/read/yumingmin@python/mi4af1 https://blog.csdn.net/penntime/article/details/140191708 https://www.cnblogs.com/liwenchao1995/p/17421496.html https://zhuanlan.zhihu.com/p/492331707\n","date":"2025-05-30T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/hello-pdm/","title":"pdm的用法"},{"content":"Buzzer复现 1、环境搭建 1.1 依赖与工具 bazel\nclang安装 我使用的是llvm-10\n1 2 3 4 5 6 7 8 # bazel sudo apt install apt-transport-https curl gnupg -y curl -fsSL https://bazel.build/bazel-release.pub.gpg | gpg --dearmor \u0026gt;bazel-archive-keyring.gpg sudo mv bazel-archive-keyring.gpg /usr/share/keyrings echo \u0026#34;deb [arch=amd64 signed-by=/usr/share/keyrings/bazel-archive-keyring.gpg] https://storage.googleapis.com/bazel-apt stable jdk1.8\u0026#34; | sudo tee /etc/apt/sources.list.d/bazel.list sudo apt update \u0026amp;\u0026amp; sudo apt install bazel sudo apt update \u0026amp;\u0026amp; sudo apt full-upgrade 设置环境变量，设置clang和clang++的路径\n1 2 export CC=clang export CXX=clang++ 运行，使用bazel构建buzzer\n1 2 3 git clone https://github.com/google/buzzer.git cd buzzer bazel build :buzzer build过程中可能会遭遇问题一，需要使用低版本的bazel才可顺利完成build\n2、run Buzzer with coverage https://github.com/google/buzzer/blob/main/docs/guides/running_with_coverage.md\n2.1 准备 bullseye.img准备\nlinux kernel准备\n注意：CONFIG_BPF=y and CONFIG_BPF_SYSCALL=y\n2.2 qemu vm运行 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 qemu-system-x86_64 \\ -m 20G \\ -smp 2 \\ -cpu host \\ -kernel PATH_TO_KERNEL_REPO/arch/x86/boot/bzImage \\ -append \u0026#34;console=ttyS0 root=/dev/sda nokaslr earlyprintk=serial net.ifnames=0\u0026#34; \\ -drive file=PATH_TO_DEBIAN_IMAGE/bullseye.img,format=raw \\ -net user,host=10.0.2.10,hostfwd=tcp:127.0.0.1:10022-:22,hostfwd=tcp:0.0.0.0:8080-:8080 \\ -net nic,model=e1000 \\ -enable-kvm \\ -nographic \\ -pidfile vm.pid \\ 2\u0026gt;\u0026amp;1 | tee vm.log # my cmd qemu-system-x86_64 \\ -m 20G \\ -smp 2 \\ -cpu host \\ -kernel ./kernel/arch/x86/boot/bzImage \\ -append \u0026#34;console=ttyS0 root=/dev/sda nokaslr earlyprintk=serial net.ifnames=0\u0026#34; \\ -drive file=/home/ranma/image/stretch.img,format=raw \\ -net user,host=10.0.2.10,hostfwd=tcp:127.0.0.1:10022-:22,hostfwd=tcp:0.0.0.0:8080-:8080 \\ -net nic,model=e1000 \\ -enable-kvm \\ -nographic \\ -pidfile vm.pid \\ 2\u0026gt;\u0026amp;1 | tee vm.log 运行成功：\n2.3 材料准备 向vm中传输一些必要文件，以及必要的准备\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 传输vmlinux scp -i PATH_TO_DEBIAN_IMAGE/bullseye.id_rsa -P 10022 PATH_TO_KERNEL_REPO/vmlinux root@localhost:~/ # 创建目录 mkdir /root/sourceFiles # 传输verifier.c文件 scp -i PATH_TO_DEBIAN_IMAGE/bullseye.id_rsa -P 10022 PATH_TO_KERNEL_REPO/kernel/bpf/verifier.c root@localhost:~/sourceFiles # 传输buzzer scp -i PATH_TO_DEBIAN_IMAGE/bullseye.id_rsa -P 10022 PATH_TO_BUZZER root@localhost:~/ # my cmd scp -i ./image/bullseye.id_rsa -P 10022 ./kernel/vmlinux root@localhost:~/ scp -i ./image/bullseye.id_rsa -P 10022 ./kernel/kernel/bpf/verifier.c root@localhost:~/sourceFiles scp -i ./image/bullseye.id_rsa -P 10022 /home/ranma/eBPF/buzzer/bazel-bin/buzzer_/buzzer root@localhost:~/ 2.4 Buzzer运行 1 2 ./buzzer -strategy=pointer_arithmetic # 直接运行./buzzer默认使用playground策略，没什么实际效果 运行效果：\n报错 错误1 看上去似乎是bazel版本过高带来的问题，安装低版本的7.4.0 bazel即可解决\n1 2 sudo apt install bazel-7.4.0 sudo ln -s /usr/bin/bazel-7.4.0 /usr/bin/bazel 错误2 传输文件vmlinux遇到qemu空间不足\n使用create-image.sh创建一个/root空间更大的image，修改SEEK参数，这里改为4G\n错误3 运行./buzzer之后没有反应\nhttps://github.com/google/buzzer/issues/58\n","date":"2025-05-29T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/buzzer/","title":"Buzzer Fuzz"},{"content":"Lora 原理 冻结原始矩阵，在原始矩阵的基础上添加一个低秩矩阵。\n微调流程 微调后的大模型使用 参考 ","date":"2025-05-29T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/hello-lora/","title":"Lora fine-tuning"},{"content":"PWN Getting Started 1、Linux Luminarium Practicing Piping Level8 grepping errors 知识点：\n1 2 3 4 5 6 7 8 9 # 通过2\u0026gt;$ 1的方式将error输出到标准输出 /challenge/run 2\u0026gt;\u0026amp;1 | grep pwn #注意是\u0026amp;符号而不是$ # grep的用法 grep [pattern] [filepath] grep X ./x.txt Level9 duplicating piped data with tee 知识点：\ntee命令的作用：tee命令可以将标准输入的内容导入到标准输出以及多个文件中\n1 /challenge/pwn | tee hint.txt | /challenge/college 随后按照提示的用法，将pwn命令的输出导入给college即可得到flag\nLevel11 split piping stderr and stdout 1 2 3 /challenge/hack 2\u0026gt; \u0026gt;(/challenge/the) | /challenge/planet /challenge/hack 2\u0026gt; \u0026gt;(/challenge/the) \u0026gt; \u0026gt;(/challenge/planet) /challenge/hack 2\u0026gt; \u0026gt;(/challenge/the) 1\u0026gt; \u0026gt;(/challenge/planet) 分流输出stderr与stdout。\n2\u0026gt; \u0026gt;(...)：将 stderr（文件描述符 2）重定向到一个子shell，子shell 中运行 /challenge/the 命令。 \u0026gt; \u0026gt;(...)：将 stdout（文件描述符 1）重定向到一个子shell，子shell 中运行 /challenge/planet 命令。 \u0026gt; \u0026gt;() 和| 的区别\n\u0026gt; \u0026gt;()： 会创建子shell 来处理重定向，可能会稍微影响性能，但在大多数情况下差异不大。 适用于需要灵活处理多个输出流的复杂场景。 |： 直接在当前 shell 中处理，性能较高。 适用于简单的命令链式调用。 Data Manipulation 这一章的关卡也挺简单的，首先是命令tr的使用方法，总结一些必要的知识点。\n1 2 3 4 5 6 7 8 9 10 # 1、替换字符串，将字符串中的abc替换为ABC，第一关就是交换一下大小写 tr abc ABC /challenge/run | tr ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ # 2、删除字符，使用-d标签 tr -d %^ /challenge/run | tr -d ^% # 3、删除特殊字符\\n，这一关提到了一个知识点，\\字符要用\\\\表示 /challenge/run | tr -d \u0026#34;\\n\u0026#34; 然后是head的使用，这些命令虽然简单，但是遗忘掉用法也很容易，还是得记录一下。\n1 2 # 4、使用head -n num输出前num行的内容 /challenge/pwn | head -n 7 | /challenge/college 最后是命令cut的使用。这条命令简单来说就是从列提取内容。\n1 2 # 5、cut的-d参数用于指出分隔符，-f则指出具体提取哪一列的内容 /challenge/run | cut -d \u0026#34; \u0026#34; -f 2 | tr -d \u0026#34;\\n\u0026#34; Shell Variables 这一部分的关卡都很简单\n总结一部分知识点\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 设置变量，这样设置的变量仅对当前shell可见 VAR=value # 使用export设置变量，这样设置的变量对当前shell及其子shell都可见 export VAR=value # 可以使用echo和env查看设置的变量 echo $VAR env # 使用$()获取命令的输出 VAR = $(cat file) # 使用read读取输入 read VAR # 使用read读取文件 read VAR \u0026lt; file Processes and Jobs 知识点总结\n1 2 3 4 5 Ctrl+Z 暂停 fg 启用并转到foreground bg 启用并转到background 运行一条命令后，可以使用 echo $? 查看exit code Perceiving Permissions 1 2 3 4 5 chown 改变文件归属 chgrp 改变文件归属组 chmod u/g/o/a +/-/= rwx [file] chmod u/g/o/a=- [file]直接清除权限 chmod u+s [file] 让其他用户以该文件的owner权限接触该文件 Silly Shenanigans 1、Bashrc Backdoor\n.bashrc中的命令会在启动时被执行，可以用作一些恶意行为。\n2、Sniffing Input\n这一关的通关思路是修改/home/zardus/.bashrc，在其目录下创建一个flag_checker，将该脚本的路径加入到PATH，使zardus执行flag_checker时执行的是该目录下的脚本，读取并打印flag。\n修改.bashrc如下：\n3、Overshared Directories\n这一关用我上一关的方法也可以成功读取flag。\n4、Trikey Linking\n这一关，zardus会向/tmp/collab/evil-commnands.txt中写入读取flag的命令，我们可以建立一个evil-commands.txt到.bashrc的链接，让zardus将命令写入.bashrc，从而读取flag。\n1 2 3 4 rm /tmp/collab/evil-commands.txt ln /home/zardus/.bashrc /tmp/collab/evil-commands.txt /challenge/victim /challenge/victim 5、Sniffing Process Arguments\n这一关很简单，通过ps -aux查看zardus的进程及其涉及到的密码，登录并读取flag。\n6、Snooping on configurations\n这一关也很简单，它主要就是为了告诉我们用户的.bashrc对于其他用户是默认可读的。我们通过查看.bashrc获取key就可以。\nDaring Destruction 1、The Fork Bomb\n这一关编写一个脚本，不停地执行fork操作，直到系统资源被耗尽。\n1 2 3 import os while True: os.system(\u0026#34;python3 test.py \u0026amp;\u0026#34;) 1 2 /challenge/check python3 test.py 不过这一关让我比较好奇的是，如果仅仅是执行python3 test.py，系统资源并不会被耗尽，而python3 test.py \u0026amp;这种background进程，则会很快消耗掉资源，这是为什么？\n原因也很简单，加上了\u0026amp;之后，进程会变为非阻塞式，程序会不断运行，而去掉之后，则会等待命令执行完毕之后再执行后面的命令，因为不会带来很大的开销。\n2、Disk-Space DoomsDay\n1 2 3 4 yes \u0026gt; ./x.txt /challenge/check rm ./x.txt /challengr/check 3、rm -rf /\n阅读/challenge/check： 当根目录下的文件被删到一定程度时就会打印flag内容。\n这一关开启两个terminal，一个执行/challenge/check，另一个执行rm -rf --no-preserve-root /，等待一段时间后，check就会打印flag。\n4、Life after rm -rf /\n这一关和上一关类似，但是/challenge/check不会直接打印/flag，而是在检测到条件满足后，将flag的值再次保存到新的/flag中。\n然而使用了rm -rf /之后，cat已经无法使用，这时候只能使用buildin内置命令，比如使用read读取文件。\n1 2 read x \u0026lt; /flag $x 5、Finding meaning after rm -rf /\n这一关和上一关的不同之处在于，flag会被保存为一个随机的名称，然而ls命令此时已经不可用，我们可以用echo读取出文件名。\n1 echo /* 2、computing 101 Your first program 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # 这一部分主要讲述了汇编代码的编写应用 汇编程序保存至.s文件中 使用syscall进行系统调用，系统调用编码保存在rax中 如： mov rax, 60 syscall 调用60号系统调用exit 使用寄存器进行传参，如exit的参数保存在rdi中 mov rdi, 42 mov rax, 60 syscall # 编译为可执行文件 编译前在文件头部加上 .intel_syntax noprefix 告知使用的是Intel汇编编码格式 as -o asm.o assemble.s ld -o exe asm.o # write syscall syscall 编号为1 三个参数 rdi 要写入的文件描述符 rsi 字符串起始地址 rdx 字符串长度 Debugging Refresher set disassembly-flavor intel 设置为intel格式\nlevel8\nwin+12 +20 +24 +33处，[rax]指向的地址为0，为nullptr，会引发segmentation fault\n因而此处直接跳过错误代码，跳转到win+35进行后续操作即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 0x580e06449951 \u0026lt;win\u0026gt;: endbr64 0x580e06449955 \u0026lt;win+4\u0026gt;: push rbp 0x580e06449956 \u0026lt;win+5\u0026gt;: mov rbp,rsp 0x580e06449959 \u0026lt;win+8\u0026gt;: sub rsp,0x10 0x580e0644995d \u0026lt;win+12\u0026gt;: mov QWORD PTR [rbp-0x8],0x0 0x580e06449965 \u0026lt;win+20\u0026gt;: mov rax,QWORD PTR [rbp-0x8] 0x580e06449969 \u0026lt;win+24\u0026gt;: mov eax,DWORD PTR [rax] 0x580e0644996b \u0026lt;win+26\u0026gt;: lea edx,[rax+0x1] 0x580e0644996e \u0026lt;win+29\u0026gt;: mov rax,QWORD PTR [rbp-0x8] 0x580e06449972 \u0026lt;win+33\u0026gt;: mov DWORD PTR [rax],edx 0x580e06449974 \u0026lt;win+35\u0026gt;: lea rdi,[rip+0x73e] # 0x580e0644a0b9 0x580e0644997b \u0026lt;win+42\u0026gt;: call 0x580e06449180 \u0026lt;puts@plt\u0026gt; 0x580e06449980 \u0026lt;win+47\u0026gt;: mov esi,0x0 0x580e06449985 \u0026lt;win+52\u0026gt;: lea rdi,[rip+0x749] # 0x580e0644a0d5 0x580e0644998c \u0026lt;win+59\u0026gt;: mov eax,0x0 0x580e06449991 \u0026lt;win+64\u0026gt;: call 0x580e06449240 \u0026lt;open@plt\u0026gt; jump *win+35 c Building a Web Server 正好借这一部分复习一下汇编的知识。这一章一方面是要经常查表，查看各个系统调用的用法，另一方面就是考察一些程序设计基本功。题目要求写一个处理GET请求和POST请求的汇编程序。\nPART1 创建socket，以及执行listen，bind等系统调用，完成一个初始化。调用bind的时需要在栈内构建一个结构体sockaddr。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 mov rdi, 2 mov rsi, 1 mov rdx, 0 mov rax, 41 # create socket syscall mov qword ptr [rsp - 24], rax mov qword ptr [rsp - 24], 0 # fd mov word ptr [rsp - 16], 2 # AF_INET (2 bytes) mov word ptr [rsp - 14], 0x5000 # Port 80 (network byte order: 0x5000) mov dword ptr [rsp - 12], 0x0000000 # 0.0.0.0 (network byte order: 0x7F000001) mov qword ptr [rsp - 8], 0 # sin_zero (8 bytes padding mov rdi, [rsp - 24] # fd lea rsi, [rsp-16] mov rdx, 16 mov rax, 49 # bind syscall mov rdi, [rsp - 24] # fd mov rsi, 0 mov rax, 50 # listen syscall PART2 接收request并创建response，使用accept获取request，从中读出要处理的文件名，将本地的文件内容write到相关的fd中。 这里我简单粗暴在栈上开辟了一个超大的空间用于保存request的内容，然后从头遍历，把文件名的后一个byte写为\\0，再把指向文件名的地址传送给系统调用open即可。accept会返回一个套接字文件描述符，往里面write文件内容即可。\nPART3 对于每一个请求，使用子进程进行处理。\n这里涉及到系统调用fork的用法。调用之后，父子进程都将从当前程序的位置往后执行，且父子进程不共享栈空间。在fork后要加一个判断逻辑，根据fork的返回值判断当前进程是父进程还是子进程，返回值为0则是子进程，否则为父进程。对于父进程，程序进入循环，接收下一个请求，对于子进程，程序处理现在的这个请求。\nPART4 处理POST请求。POST请求的内容包括要写入的文件名，要写入的内容以及长度。文件头Content-Length会说明要写入内容的长度。\n这里要处理两部分的内容，第一是匹配该文件头，第二是读取文件长度。下面的代码是我的处理逻辑。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # 获取length所处的位置 mov rdi, 0 mov rsi, 0 mov rcx, 0 mov rax, 15 xxx: mov cl, byte ptr [rsp-924+rdi] cmp cl, byte ptr [length+rsi] je xx add rdi, 1 mov rsi, 0 jmp xxx xx: add rdi, 1 add rsi, 1 cmp rsi,rax jne xxx # 计算length mov rax, 0 mov rcx, 0 add rdi, 1 xxxx: # 一个字节一个字节读，计算长度 # 如123等于 ((\u0026#39;1\u0026#39;-\u0026#39;0\u0026#39;)*10+(\u0026#39;2\u0026#39;-\u0026#39;0\u0026#39;))*10+(\u0026#39;3\u0026#39;-\u0026#39;0\u0026#39;) imul eax, 10 mov cl, byte ptr [rsp - 924+rdi] sub cl, \u0026#39;0\u0026#39; add rax, rcx add rdi, 1 cmp byte ptr [rsp-924+rdi], \u0026#39;\\r\u0026#39; jne xxxx .section .data msg: .asciz \u0026#34;HTTP/1.0 200 OK\\r\\n\\r\\n\u0026#34; length: .asciz \u0026#34;Content-Length:\u0026#34; 完整代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 .intel_syntax noprefix .globl _start .section .text _start: mov qword ptr [rsp - 24], 0 # fd mov word ptr [rsp - 16], 2 # AF_INET (2 bytes) mov word ptr [rsp - 14], 0x5000 # Port 80 (network byte order: 0x5000) mov dword ptr [rsp - 12], 0x0000000 # 127.0.0.1 (network byte order: 0x7F000001) mov qword ptr [rsp - 8], 0 # sin_zero (8 bytes padding mov rdi, 2 mov rsi, 1 mov rdx, 0 mov rax, 41 # create socket syscall # 将文件描述符保存在栈上 mov qword ptr [rsp - 24], rax mov rdi, [rsp - 24] # fd lea rsi, [rsp-16] mov rdx, 16 mov rax, 49 # bind syscall mov rdi, [rsp - 24] # fd mov rsi, 0 mov rax, 50 # listen syscall mov word ptr [rsp - 324], 0 # 保存文件内容 mov word ptr [rsp - 924], 0 # 保存读取的request mov qword ptr [rsp - 932], 0 # 备用 mov qword ptr [rsp - 940], 0 handle: mov rdi, [rsp - 24] # fd mov rsi, 0 # use 0 to represent NULL mov rdx, 0 mov rax, 43 # accept syscall mov rbx, rax mov rax, 57 # fork syscall # 这里需要判断当前进程是子进程还是主进程 cmp rax, 0 je child mov rdi, rbx mov rax, 3 syscall # close jmp handle child: mov rdi, [rsp - 24] mov rax, 3 syscall # close mov rdi, rbx lea rsi, [rsp-924] mov rdx, 600 mov rax, 0 syscall # read cmp byte ptr [rsp - 924], \u0026#39;G\u0026#39; je handle_get cmp byte ptr [rsp - 924], \u0026#39;P\u0026#39; je handle_post jmp _end handle_post: # 截取file name mov rax,0 loop1: add rax, 1 cmp byte ptr [rsp-919+rax], \u0026#39; \u0026#39; jne loop1 mov byte ptr [rsp-919+rax], 0 # 获取length所处的位置 mov rdi, 0 mov rsi, 0 mov rcx, 0 mov rax, 15 xxx: mov cl, byte ptr [rsp-924+rdi] cmp cl, byte ptr [length+rsi] je xx add rdi, 1 mov rsi, 0 jmp xxx xx: add rdi, 1 add rsi, 1 cmp rsi,rax jne xxx # 计算length mov rax, 0 mov rcx, 0 add rdi, 1 xxxx: imul eax, 10 mov cl, byte ptr [rsp - 924+rdi] sub cl, \u0026#39;0\u0026#39; add rax, rcx add rdi, 1 cmp byte ptr [rsp-924+rdi], \u0026#39;\\r\u0026#39; jne xxxx # 获取到了长度存储在rax中 mov qword ptr [rsp - 932], rax mov qword ptr [rsp - 940], rdi # open file lea rdi, [rsp - 919] mov rsi, 0x41 mov rdx, 0777 mov rax, 2 syscall mov rcx, [rsp - 940] add rcx, 4 mov rdi, rax lea rsi, [rsp-924+rcx] mov rdx, [rsp - 932] mov rax, 1 syscall # write mov rax, 3 syscall # close mov rdi, rbx lea rsi, [msg] mov rdx, 19 mov rax, 1 syscall # write msg jmp _end handle_get: # 截取file name mov rax,0 loop2: add rax, 1 cmp byte ptr [rsp-920+rax], \u0026#39; \u0026#39; jne loop2 mov byte ptr [rsp-920+rax], 0 # 根据GET或者POST选择不同的策略 # open file lea rdi, [rsp - 920] mov rsi, 0 mov rdx, 16 mov rax, 2 syscall # read file mov rdi, rax lea rsi, [rsp-324] mov rdx, 300 mov rax, 0 syscall mov qword ptr [rsp-932], rax mov rax, 3 syscall # close mov rdi, rbx lea rsi, [msg] mov rdx, 19 mov rax, 1 syscall # write mov rdi, rbx lea rsi, [rsp-324] mov rdx, [rsp-932] mov rax, 1 syscall # write mov rdi, rbx mov rax, 3 syscall # close _end: mov rdi, 0 mov rax, 60 # SYS_exit syscall .section .data msg: .asciz \u0026#34;HTTP/1.0 200 OK\\r\\n\\r\\n\u0026#34; length: .asciz \u0026#34;Content-Length:\u0026#34; Playing With Programs Program Misuse 这一关讲述了用各种命令获取flag。\ncat、more、less、tail、head、vim、emacs、nano，这些命令都可以直接读取。\n这里面，我对emacs确实稍微没那么了解，使用也很少，它其实也是一种文本编辑器。\n紧随其后的其他命令就没那么直接了。\nrev rev命令，其实就是reverse，它会把文件内容倒着输出，每一行内容都反向输出。那么我们要做的就是将flag反向输出的内容保存到一个文件里，再反向输出一次，就可以得到flag了。\n1 2 /challenge/rev /flag \u0026gt; ./galf /challenge/rev ./galf od、hd、xxd 这三个都是进制查看工具，hd即hexdump应用稍微广泛一些。\nod命令，全称为octal dump。是Linux中用于以八进制和其他格式（如十六进制、十进制和ASCII）显示文件内容的工具。这个命令在查看通常不易读的文件，如编译过的二进制文件时非常有用。\n常用选项\n-b：以单字节八进制显示文件内容。\n-c：以ASCII字符显示文件内容。\n-x：将输入转换为十六进制格式。\n-d：将输入转换为十进制格式。\n-j：跳过文件的初始字节数。\n-N：限制输出的字节数。\n-w：自定义输出的宽度。\n-v：输出重复的值。\n1 /challenge/od -c /flag hd，全名hexdump，功能和od似乎差不多，也是用各种进制的形式显示文件内容。\n1 /challenge/hd -c /flag xxd同理。\n1 /challenge/xxd /flag base32、base64 这两个命令都是用来加解码的。只是编码的格式不一样而已。\n1 2 3 4 5 /challenge/base32 /flag \u0026gt; ./galf /challenge/base32 -d ./galf /challenge/base64 /flag \u0026gt; ./galf /challenge/base64 -d ./galf split split命令可以将大文件分割为多个小文件，默认情况下会创建每一千行一个新文件。\n-l 指定分割行数\n-b 指定分割的文件大小\n-d 将分割后的文件名以数字结尾\n1 2 /challenge/split -l 1 /flag xx cat xxaa 这个命令将文件按照每行进行分割，分隔到前缀为xx的多个文件之中。\ngzip、bzip2、zip、tar、ar、cpio、genisoimage 这几个命令就很眼熟了，都是用于压缩、备份或解压的。这几个命令又是如何运用到读取文件的呢？\ngzip，gzip进行压缩时，会默认不保留原文件，压缩后的文件以.gz后缀结尾，同时继承原文件的权限信息。\n-d：解压缩 .gz 文件。相当于使用 gunzip 命令。 -k：保留原始文件，不删除。 -r：递归压缩目录下的所有文件。 -v：显示详细的压缩或解压缩过程。 -c: 输出到标准输出 1 2 3 gzip /flag # -d 进行解压，-c则输出到标准输出，从而显示文件内容 gzip -d -c /flag.gz bzip2的用法类似，多了一个-z参数表示压缩，压缩后文件后缀为bz2。\n1 2 bzip2 -z /flag bzip2 -d -c /flag.bz2 zip的用法和前面的有一定区别。\n1 zip /flag.zip /flag 压缩之后可以直接读。\ntar和zip类似，压缩成.tar文件后直接cat读取flag，但是需要注意的是.tar.gz就没法读了。\nar命令用于建立或修改备存文件，或是从备存文件中抽取文件。\n详细的使用方法可以查看 菜鸟。\n1 2 ar ./x.bak /flag cat ./x.bak cpio是用来建立，还原备份档的工具程序，它可以加入，解开 cpio 或 tar 备份档内的文件。\n1 ls /flag | cpio -o genisoimage是一个制作ISO镜像文件的命令。\n-sort会指定一个排序指导文件，这样也可以读取/flag\n1 genisoimage -sort \u0026#34;/flag\u0026#34; Execute other commands 这些命令可以用于其他命令的执行，从而间接读取flag。\nenv可用于执行其他命令。\n1 env cat /flag find的flag -exec可用于执行其他命令。-exec表示对每个找到的结果执行后续命令，cat {}会对每个找到的文件执行cat命令，{}会被自动替换为当前找到的文件路径，\\;表示-exec参数的结束（必须转义分号）\n1 find /flag -exec cat {} \\; make，make会执行Makefile中的命令，因此我们可以编写一个Makefile，打印/flag内容。\n1 2 cat: cat /flag 编写Makefile如上，随后执行make cat\nnice以更改过的优先序来执行程序，如果未指定程序，则会印出目前的排程优先序，内定的 adjustment 为 10，范围为 -20（最高优先序）到 19（最低优先序）。\n具体用法参考nice。\n1 nice cat /flag timeout可以设定命令的执行结束时间。\n1 timeout 1m cat /flag stdbuf 是一个用于修改标准流缓冲模式和大小的命令。它可以调整标准输入、标准输出和标准错误流的缓冲模式，使数据能够及时输出到下一级管道。\n缓冲类型分为三种：\n无缓冲：数据立即输出，不进行缓冲。\n行缓冲：数据在遇到换行符时输出。\n全缓冲：数据在缓冲区满时输出。\n1 stdbuf -i0 cat /flag setarch命令可以设置某个程序运行所需的CPU架构或功能标志。这对于在具有不同CPU架构的系统上运行二进制文件，或测试程序在不同CPU特性下的行为特别有用。setarch --list可以查看支持的架构。\n1 setarch x86_64 cat /flag watch可以周期性地执行给定的指令，并将输出结果显示在标准输出设备上。它可以帮助用户监测命令的运行结果，避免手动重复执行命令。\n需要注意的是watch cat /flag也可以执行cat命令，但会遇到权限不够的情况。这是因为watch cat是通过shell执行命令的，相当于sh -c cat /flag，权限继承于shell，而watch -x cat /flag中，cat以watch的子进程执行，继承了watch的权限。\n1 watch -x cat /flag socat是一个网络工具，它可以在两个端口之间建立虚拟通道，将数据从一个端口转发到另一个端口，同时支持很多网络协议。这里将命令执行内容转发到stdout。\n1 socat exec:\u0026#34;cat /flag\u0026#34; stdout SQL 这一章的内容主要讲述了sql的基础语法。这里我只总结一部分有意思的内容。\n1、substr的用法\n包含三个参数：目标字符串，起始（需要注意的是，sql字符串的第一个字符下标为1），长度。\n1 select text from table where substr(text,1,3)=\u0026#34;pwn\u0026#34; 2、sqlite_master表\n在SQLite数据库中，sqlite_master是一个存储数据库元信息的特殊表，它会在每个SQLite数据库创建时自动生成。这个表包含了数据库中所有其他表、索引、触发器和视图的描述信息。\n这个表包含的字段有：\ntype: 记录项目的类型，如table、index、view、trigger。\nname: 记录项目的名称，如表名、索引名等。\ntbl_name: 记录所从属的表名，对于表来说，该列就是表名本身。\nrootpage: 记录项目在数据库页中存储的编号。对于视图和触发器，该列值为0或者NULL。\nsql: 记录创建该项目的SQL语句。\nSQL的语法我从一开始进入大学学习计算机时就有接触，但是没有什么很高深的应用，只是做一些简单的增删改查以及数据库的管理。但是在安全领域以及数据库落地，SQL的使用还是很重要的。如SQL注入，以及高效mysql。\n","date":"2025-05-29T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/hello-pwn.college/","title":"pwn.college Getting Started"},{"content":"Syz-Repro分析 syzkaller/tools/syz-repro/repro.go at master · google/syzkaller\nsyz-repro的使用 1 ./bin/syz-repro -config=my.cfg /path/to/crash/log 使用syz-repro对log中包含的prog进行复现，这个流程包括\n1、提取出可以触发crash的初始prog\n2、对这个prog进行简化，基本采用的是逐个syscall削减简化\n3、对prog的参数等进行简化\n4、将prog转化为C poc\n5、对C poc进行简化\n程序最小化 pkg/repro/repro.go Run runInner reproCtx.run()\nminimizeProg对extract出来的程序进行minimize，在这之中调用prog.Minimize进行简化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // Minimize calls and arguments. func (ctx *reproContext) minimizeProg(res *Result) (*Result, error) { ctx.reproLogf(2, \u0026#34;minimizing guilty program\u0026#34;) start := time.Now() defer func() { ctx.stats.MinimizeProgTime = time.Since(start) }() mode := prog.MinimizeCrash if ctx.fast { mode = prog.MinimizeCallsOnly } res.Prog, _ = prog.Minimize(res.Prog, -1, mode, func(p1 *prog.Prog, callIndex int) bool { if len(p1.Calls) == 0 { // We do want to keep at least one call, otherwise tools/syz-execprog // will immediately exit. return false } ret, err := ctx.testProg(p1, res.Duration, res.Opts, false) if err != nil { ctx.reproLogf(2, \u0026#34;minimization failed with %v\u0026#34;, err) return false } return ret.Crashed }) return res, nil } 这里会调用prog中的Minimize函数对程序进行简化\n包含的参数：\n1、prog 程序列表\n2、index 开始简化的syscall下标\n3、mode 简化模式\n4、pred 测试函数，这个函数会对简化后的程序进行测试，观察其能否触发Bug\nprog minimization.go中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 Minimize函数中调用removeCalls进行简化，移除不必要的 syscall p0, callIndex0 = removeCalls(p0, callIndex0, pred) func removeCalls(p0 *Prog, callIndex0 int, pred minimizePred) (*Prog, int) { if callIndex0 \u0026gt;= 0 \u0026amp;\u0026amp; callIndex0+2 \u0026lt; len(p0.Calls) { // It\u0026#39;s frequently the case that all subsequent calls were not necessary. // Try to drop them all at once. p := p0.Clone() for i := len(p0.Calls) - 1; i \u0026gt; callIndex0; i-- { p.RemoveCall(i) } if pred(p, callIndex0, statMinRemoveCall, \u0026#34;trailing calls\u0026#34;) { p0 = p } } if callIndex0 != -1 { p0, callIndex0 = removeUnrelatedCalls(p0, callIndex0, pred) } //这里可以看到是逐个syscall尝试进行移除的 for i := len(p0.Calls) - 1; i \u0026gt;= 0; i-- { if i == callIndex0 { continue } callIndex := callIndex0 if i \u0026lt; callIndex { callIndex-- } p := p0.Clone() p.RemoveCall(i) if !pred(p, callIndex, statMinRemoveCall, fmt.Sprintf(\u0026#34;call %v\u0026#34;, i)) { continue } p0 = p callIndex0 = callIndex } return p0, callIndex0 } 对crash log的处理 log里面存放的内容：\n1、minimize之前的prog\n2、minimize这个过程的prog，以及是否crashed\n3、C程序的生成以及minimize\nminimize的方式\nprog/minimization.go Minimize对程序进行minimize处理\n处理log的方式\nprog/parse.go ParseLog对log文件进行处理\n1 2 3 4 5 6 7 函数 `ParseLog` 处理日志的方式如下： 1. 初始化一个 `LogEntry` 结构体和一些变量。 2. 通过循环逐行读取日志数据。 3. 如果行中包含 \u0026#34;executing program \u0026#34;，则解析并创建一个新的 `LogEntry`。 4. 将当前行追加到 `cur` 中，并尝试反序列化为程序。 5. 如果反序列化成功并且存在故障调用，则设置相应的故障属性。 6. 最后，将所有解析的 `LogEntry` 返回。 Log处理 可以只在log里面放一个最原始的未简化的prog\n后面程序会先尝试复现这个prog，并且会记录所有相关的时间\n实验测试结果\n结果保存 复现的结果保存到相关的文件里。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 fmt.Printf(\u0026#34;opts: %+v crepro: %v\\n\\n\u0026#34;, res.Opts, res.CRepro) //将程序序列化，写入相关文件 progSerialized := res.Prog.Serialize() fmt.Printf(\u0026#34;%s\\n\u0026#34;, progSerialized) if err = osutil.WriteFile(*flagOutput, progSerialized); err == nil { fmt.Printf(\u0026#34;program saved to %s\\n\u0026#34;, *flagOutput) } else { log.Logf(0, \u0026#34;failed to write prog to file: %v\u0026#34;, err) } if res.Report != nil \u0026amp;\u0026amp; *flagTitle != \u0026#34;\u0026#34; { recordTitle(res, *flagTitle) } if res.CRepro { recordCRepro(res, *flagCRepro) } if *flagStrace != \u0026#34;\u0026#34; { result := repro.RunStrace(res, cfg, reporter, pool) recordStraceResult(result, *flagStrace) } ","date":"2025-05-29T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/syz-repro/","title":"Syz-repro"},{"content":"Welcome to Hugo theme Stack. This is your first post. Edit or delete it, then start writing!\nFor more information about this theme, check the documentation: https://stack.jimmycai.com/\nThis is apowerfulmei!!!\nWant a site like this? Check out hugo-theme-stack-stater\nPhoto by Pawel Czerwinski on Unsplash\n","date":"2022-03-06T00:00:00Z","image":"https://apowerfulmei.github.io/p/hello-world/cover_hu_e95a4276bf860a84.jpg","permalink":"https://apowerfulmei.github.io/p/hello-world/","title":"Hello World"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] One line code block 1 \u0026lt;p\u0026gt;A paragraph\u0026lt;/p\u0026gt; List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL + ALT + Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nThe above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-09-07T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/markdown-syntax-guide/","title":"Markdown Syntax Guide"},{"content":"Hugo theme Stack supports the creation of interactive image galleries using Markdown. It\u0026rsquo;s powered by PhotoSwipe and its syntax was inspired by Typlog.\nTo use this feature, the image must be in the same directory as the Markdown file, as it uses Hugo\u0026rsquo;s page bundle feature to read the dimensions of the image. External images are not supported.\nSyntax 1 ![Image 1](1.jpg) ![Image 2](2.jpg) Result Photo by mymind and Luke Chesser on Unsplash\n","date":"2023-08-26T00:00:00Z","image":"https://apowerfulmei.github.io/p/image-gallery/2_hu_3e58a979f20e4e46.jpg","permalink":"https://apowerfulmei.github.io/p/image-gallery/","title":"Image gallery"},{"content":"For more details, check out the documentation.\nBilibili video Tencent video YouTube video Generic video file Your browser doesn't support HTML5 video. Here is a link to the video instead. Gist GitLab Quote Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n― A famous person, The book they wrote Photo by Codioful on Unsplash\n","date":"2023-08-25T00:00:00Z","image":"https://apowerfulmei.github.io/p/shortcodes/cover_hu_5667347daefb4230.jpg","permalink":"https://apowerfulmei.github.io/p/shortcodes/","title":"Shortcodes"},{"content":"Stack has built-in support for math typesetting using KaTeX.\nIt\u0026rsquo;s not enabled by default side-wide, but you can enable it for individual posts by adding math: true to the front matter. Or you can enable it side-wide by adding math = true to the params.article section in config.toml.\nInline math This is an inline mathematical expression: $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$\n1 $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$ Block math $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$ 1 2 3 $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$ $$ f(x) = \\int_{-\\infty}^\\infty\\hat f(\\xi)\\,e^{2 \\pi i \\xi x}\\,d\\xi $$ 1 2 3 $$ f(x) = \\int_{-\\infty}^\\infty\\hat f(\\xi)\\,e^{2 \\pi i \\xi x}\\,d\\xi $$ ","date":"2023-08-24T00:00:00Z","permalink":"https://apowerfulmei.github.io/p/math-typesetting/","title":"Math Typesetting"}]